{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-17T09:05:00.491693Z","iopub.execute_input":"2022-02-17T09:05:00.492269Z","iopub.status.idle":"2022-02-17T09:05:00.498272Z","shell.execute_reply.started":"2022-02-17T09:05:00.492233Z","shell.execute_reply":"2022-02-17T09:05:00.497515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport pandas as pd\nfrom glob import glob\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport gc\n\ndim = 100  # px to scale","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:00.49982Z","iopub.execute_input":"2022-02-17T09:05:00.500061Z","iopub.status.idle":"2022-02-17T09:05:00.511351Z","shell.execute_reply.started":"2022-02-17T09:05:00.500033Z","shell.execute_reply":"2022-02-17T09:05:00.510526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Path","metadata":{}},{"cell_type":"code","source":"\noutside_path ='../input/happy-whale-and-dolphin/'\npath = '../input/happy-whale-and-dolphin/train_images/*.jpg' \nfiles = glob(path)\nprint(os.listdir(outside_path))\nprint(files[:10])","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:00.512674Z","iopub.execute_input":"2022-02-17T09:05:00.512972Z","iopub.status.idle":"2022-02-17T09:05:00.767449Z","shell.execute_reply.started":"2022-02-17T09:05:00.512939Z","shell.execute_reply":"2022-02-17T09:05:00.765919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(outside_path+'train.csv')\nsamp_subm = pd.read_csv(outside_path+'sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:00.769222Z","iopub.execute_input":"2022-02-17T09:05:00.769986Z","iopub.status.idle":"2022-02-17T09:05:00.90516Z","shell.execute_reply.started":"2022-02-17T09:05:00.769939Z","shell.execute_reply":"2022-02-17T09:05:00.903908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number train samples:', len(train_data))\nprint('Number train images:', len(os.listdir(outside_path+'train_images/')))\nprint('Number test images:', len(os.listdir(outside_path+'test_images/')))","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:00.908851Z","iopub.execute_input":"2022-02-17T09:05:00.90925Z","iopub.status.idle":"2022-02-17T09:05:00.95849Z","shell.execute_reply.started":"2022-02-17T09:05:00.9092Z","shell.execute_reply":"2022-02-17T09:05:00.957323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:00.960464Z","iopub.execute_input":"2022-02-17T09:05:00.960864Z","iopub.status.idle":"2022-02-17T09:05:00.975079Z","shell.execute_reply.started":"2022-02-17T09:05:00.960799Z","shell.execute_reply":"2022-02-17T09:05:00.974072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.groupby(['species']).size().reset_index(name='counts')","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:00.976858Z","iopub.execute_input":"2022-02-17T09:05:00.977182Z","iopub.status.idle":"2022-02-17T09:05:01.006726Z","shell.execute_reply.started":"2022-02-17T09:05:00.977138Z","shell.execute_reply":"2022-02-17T09:05:01.005425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### load single image\n\nrow = 0\nfile = train_data.loc[row, 'image']\nspecies = train_data.loc[row, 'species']\n\nimg = cv2.imread(outside_path+'train_images/'+file)\nprint('Shape:', img.shape)\nplt.imshow(img)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:01.008891Z","iopub.execute_input":"2022-02-17T09:05:01.009238Z","iopub.status.idle":"2022-02-17T09:05:01.377867Z","shell.execute_reply.started":"2022-02-17T09:05:01.009191Z","shell.execute_reply":"2022-02-17T09:05:01.377148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot multiple whales\ndef plot_examples(category = 'bottlenose_dolphin'):\n    \"\"\" Plot 5 images of a given category \"\"\"\n    \n    fig, axs = plt.subplots(1, 5, figsize=(25, 20))\n    fig.subplots_adjust(hspace = .1, wspace=.1)\n    axs = axs.ravel()\n    temp = train_data[train_data['species']==category].copy()\n    temp.index = range(len(temp.index))\n    for i in range(5):\n        file = temp.loc[i, 'image']\n        species = temp.loc[i, 'species']\n        img = cv2.imread(outside_path+'train_images/'+file)\n        axs[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n        axs[i].set_title(species)\n        axs[i].set_xticklabels([])\n        axs[i].set_yticklabels([])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:01.378944Z","iopub.execute_input":"2022-02-17T09:05:01.379686Z","iopub.status.idle":"2022-02-17T09:05:01.388832Z","shell.execute_reply.started":"2022-02-17T09:05:01.379648Z","shell.execute_reply":"2022-02-17T09:05:01.38781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_examples(category = 'humpback_whale')","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:01.390846Z","iopub.execute_input":"2022-02-17T09:05:01.391223Z","iopub.status.idle":"2022-02-17T09:05:06.135187Z","shell.execute_reply.started":"2022-02-17T09:05:01.391176Z","shell.execute_reply":"2022-02-17T09:05:06.134113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_examples(category = 'bottlenose_dolphin')","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:06.136518Z","iopub.execute_input":"2022-02-17T09:05:06.136799Z","iopub.status.idle":"2022-02-17T09:05:11.478086Z","shell.execute_reply.started":"2022-02-17T09:05:06.136768Z","shell.execute_reply":"2022-02-17T09:05:11.476966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files[:3]","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:11.479765Z","iopub.execute_input":"2022-02-17T09:05:11.480029Z","iopub.status.idle":"2022-02-17T09:05:11.486976Z","shell.execute_reply.started":"2022-02-17T09:05:11.479998Z","shell.execute_reply":"2022-02-17T09:05:11.486156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files[1].split('/')[-1]","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:11.488599Z","iopub.execute_input":"2022-02-17T09:05:11.488887Z","iopub.status.idle":"2022-02-17T09:05:11.507702Z","shell.execute_reply.started":"2022-02-17T09:05:11.488851Z","shell.execute_reply":"2022-02-17T09:05:11.506926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### ลดจำนวนรูป RAM น้อยลง 10,000 , 10,000 , 10,000 \n#### image data loader maybe solution for low ram","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:11.511133Z","iopub.execute_input":"2022-02-17T09:05:11.512447Z","iopub.status.idle":"2022-02-17T09:05:11.522245Z","shell.execute_reply.started":"2022-02-17T09:05:11.512357Z","shell.execute_reply":"2022-02-17T09:05:11.520942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ### image less than 10,000 can use this method\n\n# trainImg = []\n# #try to get image label by finding picture name and going to match the csv file\n# trainImg_id = []\n# trainLabel = []\n\n# j = 1\n# num = len(files)\n\n# # Obtain images and resizing, obtain labels\n# for img in files:\n#     print(str(j) + \"/\" + str(num), end=\"\\r\")\n#     trainImg.append(cv2.resize(cv2.imread(img), (dim, dim)))  # Get image (with resizing)\n#     #trainLabel.append(img.split('/')[-1])  # Get image label (folder name)\n#     trainImg_id.append(img.split('/')[-1])  # Get image label (folder name)\n#     j += 1\n\n# trainImg = np.asarray(trainImg)  # Train images set\n# #trainLabel = pd.DataFrame(trainLabel)  # Train labels set","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:11.524324Z","iopub.execute_input":"2022-02-17T09:05:11.524781Z","iopub.status.idle":"2022-02-17T09:05:11.53746Z","shell.execute_reply.started":"2022-02-17T09:05:11.524735Z","shell.execute_reply":"2022-02-17T09:05:11.536296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_train_df = pd.read_csv('../input/happy-whale-and-dolphin/train.csv')\ndict_train_df","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:11.538942Z","iopub.execute_input":"2022-02-17T09:05:11.53934Z","iopub.status.idle":"2022-02-17T09:05:11.639441Z","shell.execute_reply.started":"2022-02-17T09:05:11.539304Z","shell.execute_reply":"2022-02-17T09:05:11.637981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_species = dict_train_df.groupby(['species']).size().reset_index(name='counts')\ncount_species.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:11.641833Z","iopub.execute_input":"2022-02-17T09:05:11.642187Z","iopub.status.idle":"2022-02-17T09:05:11.669785Z","shell.execute_reply.started":"2022-02-17T09:05:11.64214Z","shell.execute_reply":"2022-02-17T09:05:11.66829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_species['train_count'] = round(count_species['counts']*0.8)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:11.671533Z","iopub.execute_input":"2022-02-17T09:05:11.672005Z","iopub.status.idle":"2022-02-17T09:05:11.679617Z","shell.execute_reply.started":"2022-02-17T09:05:11.671964Z","shell.execute_reply":"2022-02-17T09:05:11.678681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_species.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:11.681305Z","iopub.execute_input":"2022-02-17T09:05:11.681819Z","iopub.status.idle":"2022-02-17T09:05:11.702112Z","shell.execute_reply.started":"2022-02-17T09:05:11.681775Z","shell.execute_reply":"2022-02-17T09:05:11.700681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"round(sum((count_species['counts'])*0.75))","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:11.703996Z","iopub.execute_input":"2022-02-17T09:05:11.704617Z","iopub.status.idle":"2022-02-17T09:05:11.716365Z","shell.execute_reply.started":"2022-02-17T09:05:11.704545Z","shell.execute_reply":"2022-02-17T09:05:11.714932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_train_df[dict_train_df['image'] == '80b5373b87942b.jpg'].reset_index(drop=True)['species'][0]","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:11.718159Z","iopub.execute_input":"2022-02-17T09:05:11.718428Z","iopub.status.idle":"2022-02-17T09:05:11.749675Z","shell.execute_reply.started":"2022-02-17T09:05:11.718399Z","shell.execute_reply":"2022-02-17T09:05:11.748052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:11.751094Z","iopub.execute_input":"2022-02-17T09:05:11.752239Z","iopub.status.idle":"2022-02-17T09:05:12.533375Z","shell.execute_reply.started":"2022-02-17T09:05:11.752182Z","shell.execute_reply":"2022-02-17T09:05:12.532019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:12.535055Z","iopub.execute_input":"2022-02-17T09:05:12.53532Z","iopub.status.idle":"2022-02-17T09:05:13.300914Z","shell.execute_reply.started":"2022-02-17T09:05:12.535286Z","shell.execute_reply":"2022-02-17T09:05:13.299643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !mkdir train\n# !mkdir test\n\n# ## ./test\n# ##./train","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:13.304461Z","iopub.execute_input":"2022-02-17T09:05:13.304855Z","iopub.status.idle":"2022-02-17T09:05:13.310233Z","shell.execute_reply.started":"2022-02-17T09:05:13.304815Z","shell.execute_reply":"2022-02-17T09:05:13.309403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# os.makedirs('./train')\n# os.makedirs('./test')","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:13.311401Z","iopub.execute_input":"2022-02-17T09:05:13.311906Z","iopub.status.idle":"2022-02-17T09:05:13.325093Z","shell.execute_reply.started":"2022-02-17T09:05:13.311866Z","shell.execute_reply":"2022-02-17T09:05:13.323765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:13.327164Z","iopub.execute_input":"2022-02-17T09:05:13.327493Z","iopub.status.idle":"2022-02-17T09:05:14.114641Z","shell.execute_reply.started":"2022-02-17T09:05:13.327449Z","shell.execute_reply":"2022-02-17T09:05:14.113396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:14.116295Z","iopub.execute_input":"2022-02-17T09:05:14.116624Z","iopub.status.idle":"2022-02-17T09:05:14.121429Z","shell.execute_reply.started":"2022-02-17T09:05:14.116577Z","shell.execute_reply":"2022-02-17T09:05:14.120634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### LOGIC to seperate and creating files\n#### loop in path ../input/happy-whale-and-dolphin/train_images\n### get each file such as andjfskhfhskfhjsdjs.jpg -> check what it is as a species from csv\n### if that folder of THAT species exist not create AND it THAT species not exist create one\n### resize the image and put the image into folder\ndim = 100\nfor x in tqdm(range(0,38275)):\n    var_x = files[x]\n    #print(var_x)\n    var_x2 = files[x].split('/')[-1]\n    #print(var_x2)\n    \n    # check image name with the dataframe\n    var_species = dict_train_df[dict_train_df['image'] == var_x2].reset_index(drop=True)['species'][0]\n    #print('this is ', var_species)\n    \n    ### check path if exist or not\n    path_temp = './train/' + str(var_species)\n#     if os.path.isdir(path):\n#         print('this is created')\n#     else:\n#         print('this is not create')\n#         path_to_create = path_temp\n#         os.makedirs(path_to_create)\n    \n    # method 2 create folder name to prevent error\n    try:\n        #print('this is not create')\n        path_to_create = path_temp\n        os.makedirs(path_to_create)\n    except:\n          #print('this is created')\n            pass\n    \n    ### resize image\n    res_image = cv2.resize(cv2.imread(var_x), (dim, dim))\n    cv2.imwrite(path_temp+'/'+var_x2, res_image)\n    #trainImg.append(cv2.resize(cv2.imread(var_x), (dim, dim)))  # Get image (with resizing)\n    \n    \n    ### put the image copy and paste into its path","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:05:14.122896Z","iopub.execute_input":"2022-02-17T09:05:14.123136Z","iopub.status.idle":"2022-02-17T10:01:08.481227Z","shell.execute_reply.started":"2022-02-17T09:05:14.123099Z","shell.execute_reply":"2022-02-17T10:01:08.477877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### 6950 pictures will take 10mins to run\n####  13400 will take 20 mins to run (158MB)\n####  38275  will take 55 mins to run (400MB)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### LOGIC to seperate and creating files range(start, stop[, step])\n#### loop in path ../input/happy-whale-and-dolphin/train_images\n### get each file such as andjfskhfhskfhjsdjs.jpg -> check what it is as a species from csv\n### if that folder of THAT species exist not create AND it THAT species not exist create one\n### resize the image and put the image into folder\ndim = 100\nfor x in tqdm(range(38276,51033)):\n    var_x = files[x]\n    #print(var_x)\n    var_x2 = files[x].split('/')[-1]\n    #print(var_x2)\n    \n    # check image name with the dataframe\n    var_species = dict_train_df[dict_train_df['image'] == var_x2].reset_index(drop=True)['species'][0]\n    #print('this is ', var_species)\n    \n    ### check path if exist or not\n    path_temp = './test/' + str(var_species)\n#     if os.path.isdir(path):\n#         print('this is created')\n#     else:\n#         print('this is not create')\n#         path_to_create = path_temp\n#         os.makedirs(path_to_create)\n    \n    # method 2 create folder name to prevent error\n    try:\n        #print('this is not create')\n        path_to_create = path_temp\n        os.makedirs(path_to_create)\n    except:\n          #print('this is created')\n            pass\n    \n    ### resize image\n    res_image = cv2.resize(cv2.imread(var_x), (dim, dim))\n    cv2.imwrite(path_temp+'/'+var_x2, res_image)\n    #trainImg.append(cv2.resize(cv2.imread(var_x), (dim, dim)))  # Get image (with resizing)\n    \n    \n    ### put the image copy and paste into its path","metadata":{"execution":{"iopub.status.busy":"2022-02-17T10:01:08.486796Z","iopub.execute_input":"2022-02-17T10:01:08.488253Z","iopub.status.idle":"2022-02-17T10:19:44.476655Z","shell.execute_reply.started":"2022-02-17T10:01:08.488177Z","shell.execute_reply":"2022-02-17T10:19:44.47576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lst_species = []\n# for x in range(len(trainImg_id)):\n#     image_jpg = trainImg_id[x]\n    \n#     #var_species = dict_train_df[dict_train_df['image'] == image_jpg]['species']\n#     var_species = dict_train_df[dict_train_df['image'] == image_jpg].reset_index(drop=True)['species'][0]\n#     lst_species.append(var_species)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T10:19:44.47849Z","iopub.execute_input":"2022-02-17T10:19:44.479362Z","iopub.status.idle":"2022-02-17T10:19:44.483251Z","shell.execute_reply.started":"2022-02-17T10:19:44.479322Z","shell.execute_reply":"2022-02-17T10:19:44.482635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path2 = \"./train\"\ndir_list = os.listdir(path2)\nprint(dir_list[0])\nprint(\"Files and directories in '\", dir_list, \"' :\") ","metadata":{"execution":{"iopub.status.busy":"2022-02-17T10:19:44.48468Z","iopub.execute_input":"2022-02-17T10:19:44.485078Z","iopub.status.idle":"2022-02-17T10:19:44.501625Z","shell.execute_reply.started":"2022-02-17T10:19:44.485035Z","shell.execute_reply":"2022-02-17T10:19:44.500248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(dir_list)):\n    path3 = \"./train\" + '/' + str(dir_list[i])\n    #print(path3)\n    dir_list1 = os.listdir(path3)\n    #print(dir_list1)\n    #print(\"Files and directories in '\", dir_list1, \"' :\") ","metadata":{"execution":{"iopub.status.busy":"2022-02-17T10:19:44.503948Z","iopub.execute_input":"2022-02-17T10:19:44.504621Z","iopub.status.idle":"2022-02-17T10:19:44.573018Z","shell.execute_reply.started":"2022-02-17T10:19:44.504526Z","shell.execute_reply":"2022-02-17T10:19:44.570668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# datagen = ImageDataGenerator(rotation_range=20,\n#                             zoom_range=0.15,\n#                             width_shift_range=0.2,\n#                             height_shift_range=0.2,\n#                             shear_range=0.15,\n#                             horizontal_flip=True,\n#                             vertical_flip=True,\n#                             brightness_range=[0.4,1],\n#                             rescale=1.0/255.0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### prepare folder & prepare image\n!pip install scikit-plot\nfrom tensorflow import keras\nimport tensorflow as tf\nfrom keras.utils.np_utils import to_categorical   \n\n# Define the class name (must be corresponded to folder name of each class)\nclass_list = os.listdir('./train') #class name from train folder\n\n# Normalize image function\nload_func = lambda x:x/255\n#Image Augmentation\nfrom keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(rotation_range=20,\n                            zoom_range=0.15,\n                            width_shift_range=0.2,\n                            height_shift_range=0.2,\n                            shear_range=0.15,\n                            horizontal_flip=True,\n                            vertical_flip=True,\n                            brightness_range=[0.4,1],\n                            preprocessing_function=load_func)\n\n# Train and test folder (including sub folders for each class above)\ntrain_path = './train'\ntest_path = './test'\n\n# Image size\ntarget_size = (100, 100)\n\n# load and iterate training dataset\ntrain_it = datagen.flow_from_directory(train_path, class_mode='categorical', batch_size=16,target_size=target_size,classes=class_list,shuffle=True)\n#FALSE SHUFFLEEE____________________++++++++++++++++++\ntest_it  = datagen.flow_from_directory(test_path, class_mode='categorical', batch_size=16,target_size=target_size,classes=class_list,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T10:23:06.64732Z","iopub.execute_input":"2022-02-17T10:23:06.648727Z","iopub.status.idle":"2022-02-17T10:23:29.715945Z","shell.execute_reply.started":"2022-02-17T10:23:06.64866Z","shell.execute_reply":"2022-02-17T10:23:29.714691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ### prepare folder & prepare image\n# !pip install scikit-plot\n# from tensorflow import keras\n# import tensorflow as tf\n# from keras.utils.np_utils import to_categorical   \n\n# # Define the class name (must be corresponded to folder name of each class)\n# class_list = os.listdir('./train') #class name from train folder\n\n# # Normalize image function\n# load_func = lambda x:x/255\n\n# datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=load_func)\n\n# # Train and test folder (including sub folders for each class above)\n# train_path = './train'\n# test_path = './test'\n\n# # Image size\n# target_size = (100, 100)\n\n# # load and iterate training dataset\n# train_it = datagen.flow_from_directory(train_path, class_mode='categorical', batch_size=16,target_size=target_size,classes=class_list,shuffle=True)\n# #FALSE SHUFFLEEE____________________++++++++++++++++++\n# test_it  = datagen.flow_from_directory(test_path, class_mode='categorical', batch_size=16,target_size=target_size,classes=class_list,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T10:23:06.64732Z","iopub.execute_input":"2022-02-17T10:23:06.648727Z","iopub.status.idle":"2022-02-17T10:23:29.715945Z","shell.execute_reply.started":"2022-02-17T10:23:06.64866Z","shell.execute_reply":"2022-02-17T10:23:29.714691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_datagen = train_data_gen.class_indices\ndf_dict_meaning = pd.DataFrame.from_dict(dict_datagen)\ndf_dict_meaning.to_csv('df_dict_meaning1.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-17T16:44:23.457623Z","iopub.execute_input":"2022-02-17T16:44:23.457898Z","iopub.status.idle":"2022-02-17T16:44:23.535672Z","shell.execute_reply.started":"2022-02-17T16:44:23.457868Z","shell.execute_reply":"2022-02-17T16:44:23.534744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"create model\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import Xception\nfrom tensorflow.keras.preprocessing import image","metadata":{"execution":{"iopub.status.busy":"2022-02-17T10:23:29.718071Z","iopub.execute_input":"2022-02-17T10:23:29.718345Z","iopub.status.idle":"2022-02-17T10:23:29.72675Z","shell.execute_reply.started":"2022-02-17T10:23:29.718311Z","shell.execute_reply":"2022-02-17T10:23:29.725261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #### RUN ONE EPOCH to check the model size\n# # model\n# from tensorflow.keras import optimizers\n# from tensorflow.keras.models import load_model\n# from keras.models import Sequential\n# from keras.layers import Dense, Dropout, Flatten\n# from keras.layers import BatchNormalization, GlobalAveragePooling2D\n# from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n# #from keras.applications import Xception\n\n\n# num_classes = 30\n# learning_rate = 0.001\n# batch_size = 16\n\n# base_model = Xception(input_shape=(dim, dim, 3), include_top=False,weights='imagenet')\n\n# base_model.trainable = False\n\n# model = Sequential([\n#     base_model,\n#     GlobalAveragePooling2D(),\n#     Dense(100, activation=\"relu\"),\n#     BatchNormalization(trainable = True,axis=1),\n    \n#     Dropout(0.5),\n    \n#     Dense(50, activation=\"relu\"),\n#     BatchNormalization(trainable = True,axis=1),\n    \n#     Dense(num_classes,activation='softmax')\n# ])\n\n\n# model.compile(optimizer = optimizers.Nadam(learning_rate=learning_rate),\n#               loss = 'categorical_crossentropy',\n#               metrics=['accuracy'])\n\n# # callbacks = [ EarlyStopping(monitor='val_loss', patience=5, verbose=0), \n# #               ModelCheckpoint(weights, monitor='val_loss', save_best_only=True, verbose=0),\n# #               ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)]\n\n# result = model.fit(train_it, verbose = 1,\n#                    batch_size=batch_size, epochs=25, validation_data=test_it)\n\n# (loss, accuracy) = model.evaluate(test_it)\n\n# print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))","metadata":{"execution":{"iopub.status.busy":"2022-02-18T03:32:52.451187Z","iopub.execute_input":"2022-02-18T03:32:52.451586Z","iopub.status.idle":"2022-02-18T03:32:52.469682Z","shell.execute_reply.started":"2022-02-18T03:32:52.451465Z","shell.execute_reply":"2022-02-18T03:32:52.469064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ลองเปลี่ยนดู train 1 epoch","metadata":{"execution":{"iopub.status.busy":"2022-02-17T16:34:55.987552Z","iopub.execute_input":"2022-02-17T16:34:55.988206Z","iopub.status.idle":"2022-02-17T16:34:56.007691Z","shell.execute_reply.started":"2022-02-17T16:34:55.988085Z","shell.execute_reply":"2022-02-17T16:34:56.006843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import load_model\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import BatchNormalization, GlobalAveragePooling2D\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n#from keras.applications import Xception\n\n\nnum_classes = 30\nlearning_rate = 0.001\nbatch_size = 32\n\nbase_model = Xception(input_shape=(dim, dim, 3), include_top=False,weights='imagenet')\n\nbase_model.trainable = False\n\nmodel = Sequential([\n    base_model,\n    GlobalAveragePooling2D(),\n    Dense(100, activation=\"relu\"),\n    BatchNormalization(trainable = True,axis=1),\n    \n    Dropout(0.5),\n    \n    Dense(50, activation=\"relu\"),\n    BatchNormalization(trainable = True,axis=1),\n    \n    Dense(num_classes,activation='softmax')\n])\n\n\nmodel.compile(optimizer = optimizers.Nadam(learning_rate=learning_rate),\n              loss = 'categorical_crossentropy',\n              metrics=['accuracy'])\n\n# callbacks = [ EarlyStopping(monitor='val_loss', patience=5, verbose=0), \n#               ModelCheckpoint(weights, monitor='val_loss', save_best_only=True, verbose=0),\n#               ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)]\n\nresult = model.fit(train_it, verbose = 1,\n                   batch_size=batch_size, epochs=16, validation_data=test_it)\n\n(loss, accuracy) = model.evaluate(test_it)\n\nprint(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))","metadata":{"execution":{"iopub.status.busy":"2022-02-17T10:23:29.728489Z","iopub.execute_input":"2022-02-17T10:23:29.728864Z","iopub.status.idle":"2022-02-17T14:57:58.157912Z","shell.execute_reply.started":"2022-02-17T10:23:29.728819Z","shell.execute_reply":"2022-02-17T14:57:58.153908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### each epoch is 1000s  for  38276 trainning files\n### dataset/n of batchsize = 3XXXX/16\n### all the batch size should be equal","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.plot(result.history['accuracy'], label='train')\n# plt.plot(result.history['val_accuracy'], label='valid')\n# plt.legend(loc='upper left')\n# plt.title('Model accuracy')\n# plt.ylabel('Accuracy')\n# plt.xlabel('Epoch')\n# plt.show()\n\n# plt.plot(result.history['loss'], label='train')\n# plt.plot(result.history['val_loss'], label='valid')\n# plt.legend(loc='upper right')\n# plt.title('Model Cost')\n# plt.ylabel('Cost')\n# plt.xlabel('Epoch')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T15:03:10.924323Z","iopub.execute_input":"2022-02-17T15:03:10.92473Z","iopub.status.idle":"2022-02-17T15:03:10.930008Z","shell.execute_reply.started":"2022-02-17T15:03:10.924689Z","shell.execute_reply":"2022-02-17T15:03:10.929282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model_whaledophin_first_16epoch_imgaug.h5')","metadata":{"execution":{"iopub.status.busy":"2022-02-17T14:58:02.962728Z","iopub.execute_input":"2022-02-17T14:58:02.963256Z","iopub.status.idle":"2022-02-17T14:58:03.708933Z","shell.execute_reply.started":"2022-02-17T14:58:02.963218Z","shell.execute_reply":"2022-02-17T14:58:03.707912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"get into xception model","metadata":{}},{"cell_type":"code","source":"base_model.trainable = True\nmodel.get_layer('xception').trainable","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=optimizers.Nadam(learning_rate=0.0006), loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# result2 = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), epochs=50, \n#                    initial_epoch=25, validation_data=(x_valid, y_valid),verbose=1)\n# result2 = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), epochs=50, \n#                    initial_epoch=25, validation_data=(x_valid, y_valid),verbose=1)\nresult2 = model.fit(train_it, verbose = 1,\n                   batch_size=batch_size, epochs=16, validation_data=test_it)\n\n(loss, accuracy) = model.evaluate(test_it)\n\nprint(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model_whaledophin_first_32epoch_xception_imgaug.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(result2.history['accuracy'], label='train')\nplt.plot(result2.history['val_accuracy'], label='valid')\nplt.legend(loc='upper left')\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.show()\n\nplt.plot(result2.history['loss'], label='train')\nplt.plot(result2.history['val_loss'], label='valid')\nplt.legend(loc='upper right')\nplt.title('Model Cost')\nplt.ylabel('Cost')\nplt.xlabel('Epoch')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# run until this cell\n# and END","metadata":{}},{"cell_type":"code","source":"#train model\n# model.fit(train_it,epochs=5, validation_data=test_it,verbose=1,workers=8)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T14:57:58.161991Z","iopub.status.idle":"2022-02-17T14:57:58.163415Z","shell.execute_reply.started":"2022-02-17T14:57:58.163178Z","shell.execute_reply":"2022-02-17T14:57:58.163207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from keras import backend as K\n# K.set_value(model.optimizer.learning_rate, 0.00003)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T14:57:58.164582Z","iopub.status.idle":"2022-02-17T14:57:58.164937Z","shell.execute_reply.started":"2022-02-17T14:57:58.164757Z","shell.execute_reply":"2022-02-17T14:57:58.16478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.save('model_whaledophin_first_16epoch.h5')","metadata":{"execution":{"iopub.status.busy":"2022-02-17T14:57:58.16618Z","iopub.status.idle":"2022-02-17T14:57:58.166507Z","shell.execute_reply.started":"2022-02-17T14:57:58.166333Z","shell.execute_reply":"2022-02-17T14:57:58.166355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"load model and develop more","metadata":{}},{"cell_type":"code","source":"# from tensorflow.keras.models import load_model","metadata":{"execution":{"iopub.status.busy":"2022-02-17T14:59:48.210614Z","iopub.execute_input":"2022-02-17T14:59:48.21101Z","iopub.status.idle":"2022-02-17T14:59:48.2205Z","shell.execute_reply.started":"2022-02-17T14:59:48.210973Z","shell.execute_reply":"2022-02-17T14:59:48.219706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load_model('')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# files[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.090577Z","iopub.status.idle":"2022-02-17T06:08:48.090915Z","shell.execute_reply.started":"2022-02-17T06:08:48.090756Z","shell.execute_reply":"2022-02-17T06:08:48.090774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get list of label in the dictionary\n# trainImg_id[:20]","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.09354Z","iopub.status.idle":"2022-02-17T06:08:48.09386Z","shell.execute_reply.started":"2022-02-17T06:08:48.093702Z","shell.execute_reply":"2022-02-17T06:08:48.093719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dict_train_df = pd.read_csv('../input/happy-whale-and-dolphin/train.csv')\n# dict_train_df","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.095609Z","iopub.status.idle":"2022-02-17T06:08:48.096304Z","shell.execute_reply.started":"2022-02-17T06:08:48.09596Z","shell.execute_reply":"2022-02-17T06:08:48.095991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lst_species = []\n# for x in range(len(trainImg_id)):\n#     image_jpg = trainImg_id[x]\n    \n#     #var_species = dict_train_df[dict_train_df['image'] == image_jpg]['species']\n#     var_species = dict_train_df[dict_train_df['image'] == image_jpg].reset_index(drop=True)['species'][0]\n#     lst_species.append(var_species)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.097448Z","iopub.status.idle":"2022-02-17T06:08:48.097732Z","shell.execute_reply.started":"2022-02-17T06:08:48.097586Z","shell.execute_reply":"2022-02-17T06:08:48.097601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# type(lst_species[0])","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.099331Z","iopub.status.idle":"2022-02-17T06:08:48.099906Z","shell.execute_reply.started":"2022-02-17T06:08:48.099716Z","shell.execute_reply":"2022-02-17T06:08:48.099737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lst_species[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.100969Z","iopub.status.idle":"2022-02-17T06:08:48.101546Z","shell.execute_reply.started":"2022-02-17T06:08:48.101377Z","shell.execute_reply":"2022-02-17T06:08:48.101395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trainLabel = pd.DataFrame(lst_species)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.102439Z","iopub.status.idle":"2022-02-17T06:08:48.102901Z","shell.execute_reply.started":"2022-02-17T06:08:48.102726Z","shell.execute_reply":"2022-02-17T06:08:48.102744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trainImg_id[:4]","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.103668Z","iopub.status.idle":"2022-02-17T06:08:48.104308Z","shell.execute_reply.started":"2022-02-17T06:08:48.104099Z","shell.execute_reply":"2022-02-17T06:08:48.104118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Image Preprocessing","metadata":{}},{"cell_type":"code","source":"# trainImg[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.105437Z","iopub.status.idle":"2022-02-17T06:08:48.106165Z","shell.execute_reply.started":"2022-02-17T06:08:48.105951Z","shell.execute_reply":"2022-02-17T06:08:48.105971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import cv2","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.106962Z","iopub.status.idle":"2022-02-17T06:08:48.107433Z","shell.execute_reply.started":"2022-02-17T06:08:48.107228Z","shell.execute_reply":"2022-02-17T06:08:48.107255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image = cv2.imread(trainImg[0]), (dim, dim)\n# plt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.108484Z","iopub.status.idle":"2022-02-17T06:08:48.108778Z","shell.execute_reply.started":"2022-02-17T06:08:48.108622Z","shell.execute_reply":"2022-02-17T06:08:48.108646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating a mask for the Green colour\n#test\n# blurImg = cv2.GaussianBlur(trainImg[0], (5, 5), 0)\n# plt.imshow(blurImg)\n# plt.show()\n# # Convert to HSV image ----> can help to tell similarity between colors\n# hsvImg = cv2.cvtColor(blurImg, cv2.COLOR_BGR2HSV)\n# plt.imshow(hsvImg)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.109913Z","iopub.status.idle":"2022-02-17T06:08:48.110222Z","shell.execute_reply.started":"2022-02-17T06:08:48.110047Z","shell.execute_reply":"2022-02-17T06:08:48.110061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def preProcessImage(Img_arr, getEx=True):\n#     clearImg = []\n#     for img in Img_arr:\n#         # Use gaussian blur\n#         blurImg = cv2.GaussianBlur(img, (5, 5), 0)   \n\n#         # Convert to HSV image\n#         hsvImg = cv2.cvtColor(blurImg, cv2.COLOR_BGR2HSV)  \n\n#         clearImg.append(hsvImg)  # Append image without backgroung\n\n#         # Show examples -> plot to show\n#         if getEx:\n#             fig = plt.figure(figsize=(10, 10))\n#             imagels = [img,blurImg,hsvImg]\n#             titlels = ['Original Image','Blur Image','HSV Image']\n#             for i in range(3):\n#                 plot = fig.add_subplot(1, 3, i + 1)\n#                 plt.xticks([]),plt.yticks([])\n#                 plot.title.set_text(titlels[i])\n#                 plt.imshow(imagels[i])\n#             plt.tight_layout()\n#             plt.show()\n#             getEx = False\n\n#     return(np.asarray(clearImg))","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.111196Z","iopub.status.idle":"2022-02-17T06:08:48.111483Z","shell.execute_reply.started":"2022-02-17T06:08:48.11133Z","shell.execute_reply":"2022-02-17T06:08:48.111345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# clearTrainImg = preProcessImage(trainImg)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.11244Z","iopub.status.idle":"2022-02-17T06:08:48.112722Z","shell.execute_reply.started":"2022-02-17T06:08:48.11257Z","shell.execute_reply":"2022-02-17T06:08:48.112585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Normalizing the train Images :   0-255 -> 0 to 1 (reduce range)\n# x_train = clearTrainImg / 255.0","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.113362Z","iopub.status.idle":"2022-02-17T06:08:48.113636Z","shell.execute_reply.started":"2022-02-17T06:08:48.113489Z","shell.execute_reply":"2022-02-17T06:08:48.113504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # n of total class\n# len(set(list(trainLabel[0])))","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.114655Z","iopub.status.idle":"2022-02-17T06:08:48.115135Z","shell.execute_reply.started":"2022-02-17T06:08:48.114877Z","shell.execute_reply":"2022-02-17T06:08:48.114912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### \n# from sklearn.preprocessing import OneHotEncoder\n\n# # Encode labels and create classes\n# enc = OneHotEncoder(categories='auto')\n# y_train = enc.fit_transform(trainLabel).toarray()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.11673Z","iopub.status.idle":"2022-02-17T06:08:48.11791Z","shell.execute_reply.started":"2022-02-17T06:08:48.117736Z","shell.execute_reply":"2022-02-17T06:08:48.117756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import StratifiedShuffleSplit\n\n# sss = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=42) # Want a balanced split for all the classes\n# for train_index, test_index in sss.split(x_train, y_train):\n#     print(\"Using {} for training and {} for validation\".format(len(train_index), len(test_index)))\n#     x_train, x_valid = x_train[train_index], x_train[test_index]\n#     y_train, y_valid = y_train[train_index], y_train[test_index]","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.118753Z","iopub.status.idle":"2022-02-17T06:08:48.119193Z","shell.execute_reply.started":"2022-02-17T06:08:48.119005Z","shell.execute_reply":"2022-02-17T06:08:48.119021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(len(x_train))\n# print(len(x_valid))\n# print(len(y_train))\n# print(len(y_valid))","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.120001Z","iopub.status.idle":"2022-02-17T06:08:48.120461Z","shell.execute_reply.started":"2022-02-17T06:08:48.120288Z","shell.execute_reply":"2022-02-17T06:08:48.120306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Image Augmentation\n# from keras.preprocessing.image import ImageDataGenerator\n\n# datagen = ImageDataGenerator(rotation_range=20,\n#                             zoom_range=0.15,\n#                             width_shift_range=0.2,\n#                             height_shift_range=0.2,\n#                             shear_range=0.15,\n#                             horizontal_flip=True,\n#                             vertical_flip=True,\n#                             brightness_range=[0.4,1],\n#                             rescale=1.0/255.0)\n# datagen.fit(x_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.121254Z","iopub.status.idle":"2022-02-17T06:08:48.121648Z","shell.execute_reply.started":"2022-02-17T06:08:48.121499Z","shell.execute_reply":"2022-02-17T06:08:48.121516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from tensorflow.keras.applications import Xception","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.122406Z","iopub.status.idle":"2022-02-17T06:08:48.122784Z","shell.execute_reply.started":"2022-02-17T06:08:48.122638Z","shell.execute_reply":"2022-02-17T06:08:48.122654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from tensorflow.keras.preprocessing import image","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.123666Z","iopub.status.idle":"2022-02-17T06:08:48.12399Z","shell.execute_reply.started":"2022-02-17T06:08:48.123808Z","shell.execute_reply":"2022-02-17T06:08:48.123829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # model\n# from tensorflow.keras import optimizers\n# from keras.models import Sequential\n# from keras.layers import Dense, Dropout, Flatten\n# from keras.layers import BatchNormalization, GlobalAveragePooling2D\n# from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n# #from keras.applications import Xception\n\n\n# num_classes = 30\n# learning_rate = 0.001\n# batch_size = 32\n\n# base_model = Xception(input_shape=(dim, dim, 3), include_top=False,weights='imagenet')\n\n# base_model.trainable = False\n\n# model = Sequential([\n#     base_model,\n#     GlobalAveragePooling2D(),\n#     Dense(100, activation=\"relu\"),\n#     BatchNormalization(trainable = True,axis=1),\n    \n#     Dropout(0.5),\n    \n#     Dense(50, activation=\"relu\"),\n#     BatchNormalization(trainable = True,axis=1),\n    \n#     Dense(num_classes,activation='softmax')\n# ])\n\n\n# model.compile(optimizer = optimizers.Nadam(learning_rate=learning_rate),\n#               loss = 'categorical_crossentropy',\n#               metrics=['accuracy'])\n\n# # callbacks = [ EarlyStopping(monitor='val_loss', patience=5, verbose=0), \n# #               ModelCheckpoint(weights, monitor='val_loss', save_best_only=True, verbose=0),\n# #               ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)]\n\n# result = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), verbose = 1,\n#                    batch_size=batch_size, epochs=25, validation_data=(x_valid, y_valid))\n\n# (loss, accuracy) = model.evaluate(x_valid, y_valid)\n\n# print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.124876Z","iopub.status.idle":"2022-02-17T06:08:48.125219Z","shell.execute_reply.started":"2022-02-17T06:08:48.125025Z","shell.execute_reply":"2022-02-17T06:08:48.125046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.plot(result.history['accuracy'], label='train')\n# plt.plot(result.history['val_accuracy'], label='valid')\n# plt.legend(loc='upper left')\n# plt.title('Model accuracy')\n# plt.ylabel('Accuracy')\n# plt.xlabel('Epoch')\n# plt.show()\n\n# plt.plot(result.history['loss'], label='train')\n# plt.plot(result.history['val_loss'], label='valid')\n# plt.legend(loc='upper right')\n# plt.title('Model Cost')\n# plt.ylabel('Cost')\n# plt.xlabel('Epoch')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.126498Z","iopub.status.idle":"2022-02-17T06:08:48.126801Z","shell.execute_reply.started":"2022-02-17T06:08:48.126641Z","shell.execute_reply":"2022-02-17T06:08:48.126662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Fine-tuning our model\n# base_model.trainable = True\n# model.get_layer('xception').trainable","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.128282Z","iopub.status.idle":"2022-02-17T06:08:48.128933Z","shell.execute_reply.started":"2022-02-17T06:08:48.128695Z","shell.execute_reply":"2022-02-17T06:08:48.128722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.compile(optimizer=optimizers.Nadam(learning_rate=0.0006), loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.130415Z","iopub.status.idle":"2022-02-17T06:08:48.131054Z","shell.execute_reply.started":"2022-02-17T06:08:48.130888Z","shell.execute_reply":"2022-02-17T06:08:48.130908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# result = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), epochs=50, \n#                    initial_epoch=25, validation_data=(x_valid, y_valid),verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.131903Z","iopub.status.idle":"2022-02-17T06:08:48.13235Z","shell.execute_reply.started":"2022-02-17T06:08:48.132159Z","shell.execute_reply":"2022-02-17T06:08:48.132184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.plot(result.history['accuracy'], label='train')\n# plt.plot(result.history['val_accuracy'], label='valid')\n# plt.legend(loc='upper left')\n# plt.title('Model accuracy')\n# plt.ylabel('Accuracy')\n# plt.xlabel('Epoch')\n# plt.show()\n\n# plt.plot(result.history['loss'], label='train')\n# plt.plot(result.history['val_loss'], label='valid')\n# plt.legend(loc='upper right')\n# plt.title('Model Cost')\n# plt.ylabel('Cost')\n# plt.xlabel('Epoch')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.133245Z","iopub.status.idle":"2022-02-17T06:08:48.133663Z","shell.execute_reply.started":"2022-02-17T06:08:48.133501Z","shell.execute_reply":"2022-02-17T06:08:48.133518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.134445Z","iopub.status.idle":"2022-02-17T06:08:48.134847Z","shell.execute_reply.started":"2022-02-17T06:08:48.1347Z","shell.execute_reply":"2022-02-17T06:08:48.134716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.compile(optimizer=optimizers.Nadam(learning_rate=0.00006), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.135627Z","iopub.status.idle":"2022-02-17T06:08:48.13601Z","shell.execute_reply.started":"2022-02-17T06:08:48.135864Z","shell.execute_reply":"2022-02-17T06:08:48.13588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# result = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), epochs=75, \n#                    initial_epoch=50, validation_data=(x_valid, y_valid),verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.13683Z","iopub.status.idle":"2022-02-17T06:08:48.137208Z","shell.execute_reply.started":"2022-02-17T06:08:48.136973Z","shell.execute_reply":"2022-02-17T06:08:48.136995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.plot(result.history['accuracy'], label='train')\n# plt.plot(result.history['val_accuracy'], label='valid')\n# plt.legend(loc='upper left')\n# plt.title('Model accuracy')\n# plt.ylabel('Accuracy')\n# plt.xlabel('Epoch')\n# plt.show()\n\n# plt.plot(result.history['loss'], label='train')\n# plt.plot(result.history['val_loss'], label='valid')\n# plt.legend(loc='upper right')\n# plt.title('Model Cost')\n# plt.ylabel('Cost')\n# plt.xlabel('Epoch')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.138393Z","iopub.status.idle":"2022-02-17T06:08:48.139272Z","shell.execute_reply.started":"2022-02-17T06:08:48.139053Z","shell.execute_reply":"2022-02-17T06:08:48.139074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"doing on test set","metadata":{}},{"cell_type":"code","source":"# ### Testing our Model on 50% 50%\n# path = '../input/happy-whale-and-dolphin/test_images/*.jpg'\n# files = glob(path)\n\n# testImg = []\n# testId = []\n# j = 1\n# num = len(files)\n\n# # Obtain images and resizing, obtain labels\n# for img in files:\n#     print(\"Obtain images: \" + str(j) + \"/\" + str(num), end='\\r')\n#     testId.append(img.split('/')[-1])  # Images id's\n#     testImg.append(cv2.resize(cv2.imread(img), (dim, dim)))\n#     j += 1\n\n# testImg = np.asarray(testImg)  # Train images set","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.140325Z","iopub.status.idle":"2022-02-17T06:08:48.141035Z","shell.execute_reply.started":"2022-02-17T06:08:48.140834Z","shell.execute_reply":"2022-02-17T06:08:48.140857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Pre-processing the test images\n\n\n# clearTestImg = preProcessImage(testImg,getEx=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.142443Z","iopub.status.idle":"2022-02-17T06:08:48.142937Z","shell.execute_reply.started":"2022-02-17T06:08:48.142773Z","shell.execute_reply":"2022-02-17T06:08:48.142793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Normalisation of the test images\n# clearTestImg = clearTestImg / 255","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.14399Z","iopub.status.idle":"2022-02-17T06:08:48.144432Z","shell.execute_reply.started":"2022-02-17T06:08:48.144232Z","shell.execute_reply":"2022-02-17T06:08:48.144258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Testing our trained Model\n# pred = model.predict(clearTestImg)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.145367Z","iopub.status.idle":"2022-02-17T06:08:48.145666Z","shell.execute_reply.started":"2022-02-17T06:08:48.145508Z","shell.execute_reply":"2022-02-17T06:08:48.145529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating the submission file\n\n\n# predNum = np.argmax(pred, axis=1)\n# predStr = []\n# for i in range(len(predNum)):\n#     predStr.append(enc.categories_[0][predNum[i]])\n    \n# res = {'file': testId, 'species': predStr}\n# res = pd.DataFrame(res)\n# res.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.146882Z","iopub.status.idle":"2022-02-17T06:08:48.147441Z","shell.execute_reply.started":"2022-02-17T06:08:48.147239Z","shell.execute_reply":"2022-02-17T06:08:48.147265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.save(\"saved_model\")","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:08:48.148921Z","iopub.status.idle":"2022-02-17T06:08:48.149587Z","shell.execute_reply.started":"2022-02-17T06:08:48.149348Z","shell.execute_reply":"2022-02-17T06:08:48.149377Z"},"trusted":true},"execution_count":null,"outputs":[]}]}