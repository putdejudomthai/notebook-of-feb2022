{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER CRF.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn==0.23.2\n",
        "!pip install sklearn_crfsuite\n",
        "!pip install pythainlp\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "jtztYXkw81zh",
        "outputId": "ccd7c907-0ebe-40fe-815f-d93717bbd32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==0.23.2\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2) (1.21.5)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.2 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.23.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sklearn_crfsuite in /usr/local/lib/python3.7/dist-packages (0.3.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.8.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (4.62.3)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.9.7)\n",
            "Requirement already satisfied: pythainlp in /usr/local/lib/python3.7/dist-packages (3.0.5)\n",
            "Requirement already satisfied: tinydb>=3.0 in /usr/local/lib/python3.7/dist-packages (from pythainlp) (4.6.1)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from pythainlp) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from tinydb>=3.0->pythainlp) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn_crfsuite\n",
        "import pandas as pd\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "from pythainlp.tag import pos_tag_sents"
      ],
      "metadata": {
        "id": "1l_2Np4q8PBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"/content/drive/MyDrive/superai/train_val_lst20_rule_based.csv\")\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/superai/test_lst20_rule_based.csv\")"
      ],
      "metadata": {
        "id": "S_v5E0jG9Zp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.groupby('sentence_id').agg(lambda x : list(x))\n",
        "test = test.groupby('sentence_id').agg(lambda x : list(x))\n"
      ],
      "metadata": {
        "id": "Q51W2ngb-PU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"POS\"] = pos_tag_sents(list(train[\"words\"]))\n",
        "test[\"POS\"] = pos_tag_sents(list(test[\"words\"]))\n"
      ],
      "metadata": {
        "id": "Ffc4kBgR_SlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"newPOS\"] = train[\"POS\"].apply(lambda x : [i[1] for i in x])\n",
        "test[\"newPOS\"] = test[\"POS\"].apply(lambda x : [i[1] for i in x])\n"
      ],
      "metadata": {
        "id": "DvEi8-EeERu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_NER_TAGS = [\n",
        "        \"O\",\n",
        "        \"B_BRN\",\n",
        "        \"B_DES\",\n",
        "        \"B_DTM\",\n",
        "        \"B_LOC\",\n",
        "        \"B_MEA\",\n",
        "        \"B_NUM\",\n",
        "        \"B_ORG\",\n",
        "        \"B_PER\",\n",
        "        \"B_TRM\",\n",
        "        \"B_TTL\",\n",
        "        \"I_BRN\",\n",
        "        \"I_DES\",\n",
        "        \"I_DTM\",\n",
        "        \"I_LOC\",\n",
        "        \"I_MEA\",\n",
        "        \"I_NUM\",\n",
        "        \"I_ORG\",\n",
        "        \"I_PER\",\n",
        "        \"I_TRM\",\n",
        "        \"I_TTL\",\n",
        "        \"E_BRN\",\n",
        "        \"E_DES\",\n",
        "        \"E_DTM\",\n",
        "        \"E_LOC\",\n",
        "        \"E_MEA\",\n",
        "        \"E_NUM\",\n",
        "        \"E_ORG\",\n",
        "        \"E_PER\",\n",
        "        \"E_TRM\",\n",
        "        \"E_TTL\",\n",
        "    ]"
      ],
      "metadata": {
        "id": "TNG0MoQn_ElR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_list = [ [ [train[\"words\"][i][j] , train[\"newPOS\"][i][j] , train[\"labels\"][i][j] ] for j in range(len(train[\"words\"][i]))]   for i in range(len(train))]\n",
        "test_list = [ [ [test[\"words\"][i][j] , test[\"newPOS\"][i][j] , test[\"labels\"][i][j]] for j in range(len(test[\"words\"][i]))]   for i in range(len(test))]\n"
      ],
      "metadata": {
        "id": "hh7in9gKNqi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLktnMWh4IUj"
      },
      "outputs": [],
      "source": [
        "def word2features(sent, i):\n",
        "    \n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word': word,\n",
        "        'postag': postag,\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        features.update({\n",
        "            '-1:postag': postag1,\n",
        "            '-1:word': word1,\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][1]\n",
        "        features.update({\n",
        "            '+1:postag': postag1,\n",
        "            '+1:word': word1,\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, postag, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, postag, label in sent]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_csv(\"train.csv\",index=False)\n",
        "test.to_csv(\"test.csv\",index=False)"
      ],
      "metadata": {
        "id": "uf4ECjy1I99P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [sent2features(s) for s in train_list]\n",
        "y_train = [sent2labels(s) for s in train_list]\n",
        "\n",
        "X_test = [sent2features(s) for s in test_list]\n",
        "y_test = [sent2labels(s) for s in test_list]"
      ],
      "metadata": {
        "id": "hHmVBY0f8cVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',\n",
        "    c1=0.1,\n",
        "    c2=0.1,\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "crf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "lAVLaBtI8sq5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29186ae6-34d5-4a77-e2be-7b4aee6c9b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
              "    keep_tempfiles=None, max_iterations=100)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = crf.predict(X_test)\n",
        "metrics.flat_f1_score(y_test, y_pred,average='weighted', labels=_NER_TAGS)"
      ],
      "metadata": {
        "id": "xzbKKORX8zYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d34384-8dae-4877-e49f-1a5af0da6c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1465: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.944462796122691"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# save\n",
        "with open('crfmodel.pkl','wb') as f:\n",
        "    pickle.dump(crf,f)"
      ],
      "metadata": {
        "id": "5ei3xx4JxuQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f=open('/content/ne_test.txt','r')\n",
        "text = f.readlines()\n",
        "input_text = []\n",
        "\n",
        "for i in range(len(text)):\n",
        "  if text[i] != \"\\n\":\n",
        "    input_text.append(text[i].replace(\" \",\"_\").replace(u\"\\xa0\",\"_\").replace(\"\\n\",\"\")) #\\xa0 คือ space ใน utf8 \n",
        "  else:\n",
        "    input_text.append(\"_\")\n",
        "\n",
        "input_text = input_text[:len(input_text)-1] # ตัด \\n ท้ายไฟล์ทิ้ง"
      ],
      "metadata": {
        "id": "-lVfHsAlz9VY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "id": "wnTW0spd0gGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pythainlp.tokenize import clause_tokenize\n",
        "\n",
        "kaggle_clause = clause_tokenize(input_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXF8vX1CxQGD",
        "outputId": "c259ce41-49ec-42bf-bc46-063df320ee9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus: lst20-cls\n",
            "- Downloading: lst20-cls 0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3738912/3738912 [00:00<00:00, 45912186.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_pos = [  [ tag[1] for tag in clause] for clause in pos_tag_sents(kaggle_clause)]\n",
        "kaggle_list = [ [ [kaggle_clause[i][j] , kaggle_pos[i][j]  ] for j in range(len(kaggle_clause[i]))]   for i in range(len(kaggle_clause))]\n"
      ],
      "metadata": {
        "id": "iaG2w1R41ERD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_input = [sent2features(s) for s in kaggle_list]\n",
        "\n"
      ],
      "metadata": {
        "id": "EmpY0FMg0foD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_pred = crf.predict(kaggle_input)\n",
        "kaggle_pred"
      ],
      "metadata": {
        "id": "TFfdk4e52zLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(kaggle_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kibfC4_s29R2",
        "outputId": "ae20bd51-575a-4c21-ae57-a72c9e65f57f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3648"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=[]\n",
        "for clause_pred in kaggle_pred:\n",
        "  prediction+=clause_pred\n",
        "len(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZUua40h3Gae",
        "outputId": "b61148e3-a9f8-4beb-e07c-ca5035672b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69561"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_input"
      ],
      "metadata": {
        "id": "2wdqCA9D3vtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id = [i+1 for i in range(len(prediction))]\n",
        "submission = pd.DataFrame({\"Id\":id,\"Predicted\":prediction})"
      ],
      "metadata": {
        "id": "7JpnA_cf3lz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission"
      ],
      "metadata": {
        "id": "gpPDgGUh4VYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv(\"submission_crf_post.csv\",index=False)"
      ],
      "metadata": {
        "id": "ohzQAAcE4NKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_tag = []\n",
        "for pos in kaggle_pos:\n",
        "  pos_tag+=pos\n",
        "len(pos_tag)"
      ],
      "metadata": {
        "id": "tEkuqc3S5F_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(len(prediction)):\n",
        "#   if pos_tag[i] == \"NTTL\" and input_text[i]!=\"_\":\n",
        "#     prediction[i]=\"B_TTL\""
      ],
      "metadata": {
        "id": "tufHx_NO5XT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(1,len(prediction)):\n",
        "\n",
        "#     if prediction[i-1][0] == \"I\" and prediction[i][0]==\"O\":\n",
        "#       if input_text[i-1] == \"_\":\n",
        "\n",
        "#         if (i+2<len(prediction) and prediction[i+2][0] in [\"E\",\"I\"]) or input_text[i]==\"_\":\n",
        "#           prediction[i]=\"I\"+prediction[i-1][1:]\n",
        "#         else :\n",
        "#           prediction[i]=\"E\"+prediction[i-1][1:] #can be B\n",
        "\n",
        "#       else :\n",
        "\n",
        "#         if i-2>=0 and prediction[i-2][0] == \"I\":\n",
        "#           prediction[i-1]=\"E\"+prediction[i-1][1:]\n",
        "#         else :\n",
        "#           prediction[i-1]=\"B\"+prediction[i-1][1:]\n",
        "\n",
        "#     elif prediction[i-1][0] == \"O\" and prediction[i][0]==\"I\":\n",
        "#       if input_text[i] == \"_\":\n",
        "#         if (i-2>=0 and prediction[i-2][0] == \"I\") or input_text[i-1]==\"_\":\n",
        "#           prediction[i-1]=\"I\"+prediction[i][1:]\n",
        "#         else :\n",
        "#           prediction[i-1]=\"B\"+prediction[i][1:]\n",
        "#       else:\n",
        "#         prediction[i]=\"B\"+prediction[i][1:]\n",
        "\n",
        "#     elif prediction[i-1][0] == \"E\" and prediction[i][0]==\"I\":\n",
        "#       if input_text[i] == \"_\":\n",
        "#         if (i-2>=0 and prediction[i-2][0] in [\"I\",\"B\"]) or input_text[i-1]==\"_\":\n",
        "#           prediction[i-1]=\"I\"+prediction[i][1:]\n",
        "#         else :\n",
        "#           prediction[i-1]=\"B\"+prediction[i][1:]\n",
        "#       else:\n",
        "#         if i-2>=0 and prediction[i-2][0] == \"I\":\n",
        "#           prediction[i-1]=\"I\"+prediction[i-1][1:]\n",
        "#         else :\n",
        "#           prediction[i-1]=\"B\"+prediction[i-1][1:]\n",
        "    \n",
        "#     elif prediction[i-1][0] == \"O\" and prediction[i][0]==\"E\":\n",
        "#       prediction[i]=\"B\"+prediction[i][1:]\n",
        "\n",
        "#     elif prediction[i-1][0] == \"E\" and prediction[i][0]==\"E\":\n",
        "#       if i-2>=0 and prediction[i-2][0] == \"I\":\n",
        "#         prediction[i-1]=\"I\"+prediction[i-1][1:]\n",
        "#       else :\n",
        "#         prediction[i]=\"B\"+prediction[i][1:]\n",
        "    \n",
        "#     elif prediction[i-1][0]==\"I\" and prediction[i][0]==\"B\":\n",
        "#       if i+1<len(prediction) and prediction[i+1][0]==\"E\":\n",
        "#         prediction[i]=\"I\"+prediction[i-1][1:]\n",
        "#       else:\n",
        "#         prediction[i]=\"E\"+prediction[i][1:]\n"
      ],
      "metadata": {
        "id": "uDfG8Km05YLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = pd.read_csv(\"/content/submission_pure_crf.csv\")[\"Predicted\"]\n",
        "post_pred = pd.read_csv(\"/content/submission_crf_post.csv\")[\"Predicted\"]"
      ],
      "metadata": {
        "id": "vhh8O4M-6bu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = []\n",
        "y_model = []\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  y_true+=y_test[i]\n",
        "  y_model+=y_pred[i]"
      ],
      "metadata": {
        "id": "Y7uENyfS-VeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true"
      ],
      "metadata": {
        "id": "RiPk_6gk-7BG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true,y_model))"
      ],
      "metadata": {
        "id": "bwLIIIg59-C2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}