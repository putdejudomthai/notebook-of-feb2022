{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Face Swap\n\n#### In this code, we will be able to exchange the faces of two photographs, from a facial recognition pattern. \n\nBased on [PySource.com code](https://pysource.com/2019/04/04/face-swapping-opencv-with-python-part-1/)\n\nJhonny Calvo","metadata":{"id":"qF7h7KYkTVeg"}},{"cell_type":"markdown","source":"### Neccessary Libraries","metadata":{"id":"4WUTS7fdGS70"}},{"cell_type":"code","source":"#matplot lib, to see the images\n%matplotlib inline\nimport matplotlib \nimport matplotlib.pyplot as plt\n\n#OpenCv is the main librarie of image manipulation\n!pip install opencv-python\nimport cv2\nimport numpy as np\nimport dlib\n\n#to visualize the images with better quality\nimport os\nfrom IPython.display import Image\n\n#to import from website\n!pip install wget\nimport wget\n\nprint('ready!')","metadata":{"id":"NUD2CSh-19qo","outputId":"596ea041-bfef-43d5-d178-48ad2db5cd04","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Getting images","metadata":{"id":"bEDKVZ9AVW7R"}},{"cell_type":"code","source":"url='https://files.alerta.rcnradio.com/alerta_bogota/public/styles/article_desktop/public/2019-10/el_man_0.jpg?itok=wWjcWmPw'\nwget.download(url, 'sa.jpg')\nurl2='https://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/Scarlett_Johansson_in_Kuwait_01b-tweaked.jpg/220px-Scarlett_Johansson_in_Kuwait_01b-tweaked.jpg'\nwget.download(url2, 'sj.jpg')\nprint('Images Downloaded!')","metadata":{"id":"KP_WHmnqxRQ_","outputId":"f7b98ad8-064a-4ba8-9028-1a750229dff5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nwe will use the following facial patterns file :","metadata":{"id":"zp7sansYW3-3"}},{"cell_type":"code","source":"pattern='../input/shape-predictor-68-face-landmarks/shape_predictor_68_face_landmarks.dat'","metadata":{"id":"lqslpqGjDQ54","outputId":"f75b76c5-5e1c-40cf-fa90-62e3a9bd1775","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Exploring Images\nImage 1-principal face","metadata":{"id":"uVzPkEjpHbq5"}},{"cell_type":"code","source":"#IMAGE 1\nimg1 = cv2.imread(\"./sj.jpg\") \nImage(\"./sj.jpg\")","metadata":{"id":"jXJW6egOzG8Y","outputId":"af3d1a56-0ef8-43f3-b2e3-59e15f9dc3f3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Image2-background body","metadata":{"id":"tTOirKwCWHbB"}},{"cell_type":"code","source":"#IMAGE 2\nimg2 = cv2.imread(\"./sa.jpg\") \nImage(\"./sa.jpg\")","metadata":{"id":"04AqkpiGG-0m","outputId":"c9bb7125-fc38-4127-8d72-26c7888ce757","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Transforming images to adecuate analysist format\n#### Let's work with image 1 first\n\nSetting both images in gray color\n","metadata":{"id":"CyNkBsKI57o7"}},{"cell_type":"code","source":"img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\nmask = np.zeros_like(img1_gray)\nplt.imshow(img1_gray, cmap='gray')\nplt.show ","metadata":{"id":"Xlbtp5E4xazF","outputId":"17a2b023-6561-4f4f-89e0-26eee6587549","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\nplt.imshow(img2_gray, cmap='gray')\nplt.show","metadata":{"id":"36rYSRVryjT2","outputId":"1ade730c-3731-4f41-f9bb-8c72d6f789ef","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Detecting face landmark\nHere, we detect the facial pattern in the images, such as the face shape as a landmark reference","metadata":{"id":"2qdz8U0Y6H5F"}},{"cell_type":"code","source":"detector = dlib.get_frontal_face_detector()\npredictor = dlib.shape_predictor(pattern)\nfaces = detector(img1_gray)\nfor face in faces:\n    landmarks = predictor(img1_gray, face)\n    landmarks_points = []\n    for n in range(0, 68):\n        x = landmarks.part(n).x\n        y = landmarks.part(n).y\n        landmarks_points.append((x, y))\n\nprint('next')","metadata":{"id":"IFcl6oTExyyA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we calculate the convex hull ","metadata":{"id":"AkovMlRY0r3Y"}},{"cell_type":"code","source":"points = np.array(landmarks_points, np.int32)\nconvexhull = cv2.convexHull(points)\nprint('next')","metadata":{"id":"g9Kkbqvjx16Q","outputId":"a089104b-5d6f-41a4-c224-ccd9901232b1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Detecting face landmark in image 2","metadata":{"id":"v-5f87BFy8n_"}},{"cell_type":"code","source":"faces2 = detector(img2_gray)\nfor face in faces2:\n  landmarks = predictor(img2_gray, face)\n  landmarks_points2 = []\n  for n in range(0, 68):\n    x = landmarks.part(n).x\n    y = landmarks.part(n).y\n    landmarks_points2.append((x, y))\n    #cv2.circle(img2, (x, y), 3, (0, 255, 0), -1) #This line help to print landmarks in the face\n    \nprint('next')","metadata":{"id":"m2rUt_izAzd8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"and convex hull to image 2","metadata":{"id":"lUkwyIMYYp9h"}},{"cell_type":"code","source":"points2 = np.array(landmarks_points2, np.int32)\nconvexhull2 = cv2.convexHull(points2)\nprint('next')","metadata":{"id":"yhylQ0ChP3nF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting the face into triangles\nWe need to divide both faces into triangles, to match the shape of both faces","metadata":{"id":"W4YvvoIfCqhY"}},{"cell_type":"markdown","source":"#### Applying Delaunay triangulation to image 1\n\"For morphing images the Delaunay triangulation provides a 'good' way to create a triangular mesh from points that are going to be moved. The triangular shapes are distorted from one image to the next \" from [Delaunay triangulation](https://en.wikibooks.org/wiki/Trigonometry/For_Enthusiasts/Delaunay_triangulation)","metadata":{"id":"WBXRzAeX1fgf"}},{"cell_type":"code","source":"rect = cv2.boundingRect(convexhull)#find the rectangle sourrounding convex hull\nsubdiv = cv2.Subdiv2D(rect)\nsubdiv.insert(landmarks_points)\ntriangles = subdiv.getTriangleList()\ntriangles = np.array(triangles, dtype=np.int32)\nfor t in triangles:\n   pt1 = (t[0], t[1])\n   pt2 = (t[2], t[3])\n   pt3 = (t[4], t[5])\n   #cv2.line(img, pt1, pt2, (0, 0, 255), 2) #this unselected lines help o vizualize the triangles \n   #cv2.line(img, pt2, pt3, (0, 0, 255), 2) #on the face\n   #cv2.line(img, pt3, pt1, (0, 0, 255), 2)\n\nprint('next')","metadata":{"id":"-eqrUtNp_Ax4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we need the next black pattern to put the face from image 1","metadata":{"id":"Q_mvIWZNZLit"}},{"cell_type":"code","source":"img2_new_face = np.zeros_like(img2)\nplt.imshow(img2_new_face)\nplt.show","metadata":{"id":"A3J47icWeuAj","outputId":"d4d9a09a-a246-418c-a94d-84e58ce73267","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" Next is a function to extract the indexes of the triangles from the landmarks point array:","metadata":{"id":"KnCHQ1oEWH5a"}},{"cell_type":"code","source":"def extract_index_nparray(nparray):\n    index = None\n    for num in nparray[0]:\n        index = num\n        break\n    return index\nprint('next')","metadata":{"id":"UlnqxXDp_Svj","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Finding the indexes of each triangle (or specific landmarks points each triangle connects).","metadata":{"id":"76eCeR1zYo4P"}},{"cell_type":"code","source":"indexes_triangles = []\nfor t in triangles:\n        pt1 = (t[0], t[1])\n        pt2 = (t[2], t[3])\n        pt3 = (t[4], t[5])\n        index_pt1 = np.where((points == pt1).all(axis=1))\n        index_pt1 = extract_index_nparray(index_pt1)\n        index_pt2 = np.where((points == pt2).all(axis=1))\n        index_pt2 = extract_index_nparray(index_pt2)\n        index_pt3 = np.where((points == pt3).all(axis=1))\n        index_pt3 = extract_index_nparray(index_pt3)\n        if index_pt1 is not None and index_pt2 is not None and index_pt3 is not None:\n            triangle = [index_pt1, index_pt2, index_pt3]\n            indexes_triangles.append(triangle)\n        #cv2.line(img, pt1, pt2, (0, 0, 255), 2)\n        #cv2.line(img, pt2, pt3, (0, 0, 255), 2)\n        #cv2.line(img, pt1, pt3, (0, 0, 255), 2)\nprint('next')","metadata":{"id":"rWn8chK6Ar4g","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Triangulation of the 2nd face from the 1st face using Delaunay Triangulation","metadata":{"id":"gumLtlpbzEC_"}},{"cell_type":"code","source":"# Triangulation of both faces\nfor triangle_index in indexes_triangles:\n    # Triangulation of the first face\n    tr1_pt1 = landmarks_points[triangle_index[0]]\n    tr1_pt2 = landmarks_points[triangle_index[1]]\n    tr1_pt3 = landmarks_points[triangle_index[2]]\n    triangle1 = np.array([tr1_pt1, tr1_pt2, tr1_pt3], np.int32)\n\n    rect1 = cv2.boundingRect(triangle1)\n    (x, y, w, h) = rect1\n    cropped_triangle = img1[y: y + h, x: x + w]\n    cropped_tr1_mask = np.zeros((h, w), np.uint8)\n    points = np.array([[tr1_pt1[0] - x, tr1_pt1[1] - y],\n                      [tr1_pt2[0] - x, tr1_pt2[1] - y],\n                      [tr1_pt3[0] - x, tr1_pt3[1] - y]], np.int32)\n    cv2.fillConvexPoly(cropped_tr1_mask, points, 255)\n    cropped_triangle = cv2.bitwise_and(cropped_triangle, cropped_triangle,\n                                       mask=cropped_tr1_mask)\n    #cv2.line(img, tr1_pt1, tr1_pt2, (0, 0, 255), 2)\n    #cv2.line(img, tr1_pt3, tr1_pt2, (0, 0, 255), 2)\n    #cv2.line(img, tr1_pt1, tr1_pt3, (0, 0, 255), 2)\n\n     # Triangulation of second face\n    tr2_pt1 = landmarks_points2[triangle_index[0]]\n    tr2_pt2 = landmarks_points2[triangle_index[1]]\n    tr2_pt3 = landmarks_points2[triangle_index[2]]\n    triangle2 = np.array([tr2_pt1, tr2_pt2, tr2_pt3], np.int32)\n    rect2 = cv2.boundingRect(triangle2)\n    (x, y, w, h) = rect2\n    cropped_triangle2 = img2[y: y + h, x: x + w]\n    cropped_tr2_mask = np.zeros((h, w), np.uint8)\n    points2 = np.array([[tr2_pt1[0] - x, tr2_pt1[1] - y],\n                       [tr2_pt2[0] - x, tr2_pt2[1] - y],\n                       [tr2_pt3[0] - x, tr2_pt3[1] - y]], np.int32)\n    cv2.fillConvexPoly(cropped_tr2_mask, points2, 255)\n    cropped_triangle2 = cv2.bitwise_and(cropped_triangle2, cropped_triangle2,\n                                       mask=cropped_tr2_mask)\n    #cv2.line(img2, tr2_pt1, tr2_pt2, (0, 0, 255), 2)\n    #cv2.line(img2, tr2_pt3, tr2_pt2, (0, 0, 255), 2)\n    #cv2.line(img2, tr2_pt1, tr2_pt3, (0, 0, 255), 2)\n    \n    # Let's Warp triangles\n    points = np.float32(points)\n    points2 = np.float32(points2)\n    M = cv2.getAffineTransform(points, points2)\n    warped_triangle = cv2.warpAffine(cropped_triangle, M, (w, h))\n    warped_triangle = cv2.bitwise_and(warped_triangle, warped_triangle, mask=cropped_tr2_mask)##\n\n    # *****Reconstructing destination face************************************************\n    img2_new_face_rect_area = img2_new_face[y: y + h, x: x + w]\n    img2_new_face_rect_area_gray= cv2.cvtColor(img2_new_face_rect_area, cv2.COLOR_BGR2GRAY)\n\n    #To remove the lines between triangles\n    _, mask_triangles_designed=cv2.threshold(img2_new_face_rect_area_gray, 1, 255, cv2.THRESH_BINARY_INV)\n    warped_triangle=cv2.bitwise_and(warped_triangle, warped_triangle, mask=mask_triangles_designed)\n\n    img2_new_face_rect_area = cv2.add(img2_new_face_rect_area, warped_triangle)\n    img2_new_face[y: y + h, x: x + w] = img2_new_face_rect_area\n\n    # Face swapped (putting 1st face into 2nd face)\n    img2_face_mask = np.zeros_like(img2_gray)\n    img2_head_mask = cv2.fillConvexPoly(img2_face_mask, convexhull2, 255)\n    img2_face_mask = cv2.bitwise_not(img2_head_mask)\n\n    img2_head_noface = cv2.bitwise_and(img2, img2, mask=img2_face_mask)\n    result = cv2.add(img2_head_noface, img2_new_face)\n\n    #plt.imshow(img2_new_face)\n    plt.imshow(result)","metadata":{"id":"YOPC0DD8MKcT","outputId":"4fb77f1b-0676-420e-843d-a4d8d503883d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next line, help to visualize triangles from images 1 and images 2\nand the warped triangle","metadata":{"id":"dH8g2UBjZl1c"}},{"cell_type":"code","source":"#cv2_imshow(cropped_triangle)#cropped triangle 1\n#cv2_imshow(cropped_triangle2)#\"cropped triangle 2\"\n#cv2_imshow(warped_triangle)#\"Warped triangle\"\n#we havent cv2_imshow on kaggle","metadata":{"id":"MCtjIFeAMavi","outputId":"a7d1c143-7468-4dcd-9b29-7e432ed63b2a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is the face from image 1, adapted to the shape of the face of image 2","metadata":{"id":"7v-jL8WtZyX1"}},{"cell_type":"code","source":"plt.imshow(img2_new_face)","metadata":{"id":"ewC0PAJ1NmSZ","outputId":"93d55438-9c7e-44f4-d317-50d2df81a70c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And here we have made space in image 2, to place the face of image 1","metadata":{"id":"epWKeGISaDPo"}},{"cell_type":"code","source":"plt.imshow(img2_head_noface)\nplt.show","metadata":{"id":"ta6mdjEYJWM3","outputId":"245bbbf6-70d2-492f-eca7-833093df500a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nThe following line helps to soften the edges of the face and the background body, as well as to place them in the same colors","metadata":{"id":"U5zeLkTIaP5z"}},{"cell_type":"code","source":"(x, y, w, h) = cv2.boundingRect(convexhull2)\ncenter_face2 = (int((x + x + w)/2), int((y + y + h)/2))\nseamlessclone= cv2.seamlessClone(result, img2, img2_head_mask, center_face2, cv2.MIXED_CLONE)","metadata":{"id":"fr1-iAXxBc2c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Result","metadata":{"id":"tC5qxB2yaegz"}},{"cell_type":"code","source":"\nplt.imshow(seamlessclone)\nplt.show","metadata":{"id":"hGPnVsUoJfSM","outputId":"9738ed5e-a907-4cb1-db1a-7d34c2e46265","trusted":true},"execution_count":null,"outputs":[]}]}