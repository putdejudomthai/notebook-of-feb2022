{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-19T09:16:43.856358Z","iopub.execute_input":"2022-02-19T09:16:43.857034Z","iopub.status.idle":"2022-02-19T09:16:43.883754Z","shell.execute_reply.started":"2022-02-19T09:16:43.856905Z","shell.execute_reply":"2022-02-19T09:16:43.882926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#matplot lib, to see the images\n%matplotlib inline\nimport matplotlib \nimport matplotlib.pyplot as plt\n\n#OpenCv is the main librarie of image manipulation\n!pip install opencv-python\nimport cv2\nimport numpy as np\nimport dlib\n\n#to visualize the images with better quality\nimport os\nfrom IPython.display import Image\n\n#to import from website\n!pip install wget\nimport wget\n\nprint('ready!')","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:16:45.705357Z","iopub.execute_input":"2022-02-19T09:16:45.70566Z","iopub.status.idle":"2022-02-19T09:17:07.548254Z","shell.execute_reply.started":"2022-02-19T09:16:45.705627Z","shell.execute_reply":"2022-02-19T09:17:07.547458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone  https://github.com/italojs/facial-landmarks-recognition","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:17:12.187885Z","iopub.execute_input":"2022-02-19T09:17:12.188152Z","iopub.status.idle":"2022-02-19T09:17:21.626248Z","shell.execute_reply.started":"2022-02-19T09:17:12.188126Z","shell.execute_reply":"2022-02-19T09:17:21.625218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:14:40.837791Z","iopub.execute_input":"2022-02-19T09:14:40.83807Z","iopub.status.idle":"2022-02-19T09:14:41.223222Z","shell.execute_reply.started":"2022-02-19T09:14:40.838042Z","shell.execute_reply":"2022-02-19T09:14:41.222395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### this is the path of image\nurl='https://files.alerta.rcnradio.com/alerta_bogota/public/styles/article_desktop/public/2019-10/el_man_0.jpg?itok=wWjcWmPw'\nwget.download(url, 'sa.jpg')\nurl2='https://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/Scarlett_Johansson_in_Kuwait_01b-tweaked.jpg/220px-Scarlett_Johansson_in_Kuwait_01b-tweaked.jpg'\nwget.download(url2, 'sj.jpg')\nprint('Images Downloaded!')\nurl3 = \"https://www.cnet.com/a/img/K9M4-6WeU10J3QC-AXwJSDxhd8M=/1200x675/2020/09/02/2b8810d6-ab1a-4bd1-8f0f-1f05cc9099c7/bond-poster.jpg\"\nwget.download(url1, 'jb.jpg')\n#jinny BP\n# url4 = \"https://www.brighttv.co.th/wp-content/uploads/2021/07/89f81a8c5ca14803a73345e8397c21b7.jpeg\"\n# wget.download(url4, 'jbp.jpg')","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:28:36.451293Z","iopub.execute_input":"2022-02-19T09:28:36.451653Z","iopub.status.idle":"2022-02-19T09:28:37.400344Z","shell.execute_reply.started":"2022-02-19T09:28:36.451617Z","shell.execute_reply":"2022-02-19T09:28:37.399546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pattern='./facial-landmarks-recognition/shape_predictor_68_face_landmarks.dat'","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:28:27.034444Z","iopub.status.idle":"2022-02-19T09:28:27.034798Z","shell.execute_reply.started":"2022-02-19T09:28:27.034614Z","shell.execute_reply":"2022-02-19T09:28:27.034631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#IMAGE 1  : principal face\nimg1 = cv2.imread(\"./jbp.jpg\") \nImage(\"./jbp.jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:20:28.371872Z","iopub.execute_input":"2022-02-19T09:20:28.372932Z","iopub.status.idle":"2022-02-19T09:20:28.382989Z","shell.execute_reply.started":"2022-02-19T09:20:28.372886Z","shell.execute_reply":"2022-02-19T09:20:28.382181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#IMAGE 2  :  Image2-background body\n\nimg2 = cv2.imread(\"./sa.jpg\") \nImage(\"./sa.jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:20:04.02203Z","iopub.execute_input":"2022-02-19T09:20:04.02253Z","iopub.status.idle":"2022-02-19T09:20:04.045158Z","shell.execute_reply.started":"2022-02-19T09:20:04.022477Z","shell.execute_reply":"2022-02-19T09:20:04.044458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\nmask = np.zeros_like(img1_gray)\nplt.imshow(img1_gray, cmap='gray')\nplt.show ","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:20:34.314158Z","iopub.execute_input":"2022-02-19T09:20:34.314477Z","iopub.status.idle":"2022-02-19T09:20:34.571877Z","shell.execute_reply.started":"2022-02-19T09:20:34.314444Z","shell.execute_reply":"2022-02-19T09:20:34.570943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\nplt.imshow(img2_gray, cmap='gray')\nplt.show","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:20:36.765744Z","iopub.execute_input":"2022-02-19T09:20:36.766057Z","iopub.status.idle":"2022-02-19T09:20:37.107164Z","shell.execute_reply.started":"2022-02-19T09:20:36.766024Z","shell.execute_reply":"2022-02-19T09:20:37.106544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nDetecting face landmark\n\nHere, we detect the facial pattern in the images, such as the face shape as a landmark reference\n","metadata":{}},{"cell_type":"code","source":"detector = dlib.get_frontal_face_detector()\npredictor = dlib.shape_predictor(pattern)\nfaces = detector(img1_gray)\nfor face in faces:\n    landmarks = predictor(img1_gray, face)\n    landmarks_points = []\n    for n in range(0, 68):\n        x = landmarks.part(n).x\n        y = landmarks.part(n).y\n        landmarks_points.append((x, y))\n\nprint('next')","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:20:39.746264Z","iopub.execute_input":"2022-02-19T09:20:39.746825Z","iopub.status.idle":"2022-02-19T09:20:41.328521Z","shell.execute_reply.started":"2022-02-19T09:20:39.746759Z","shell.execute_reply":"2022-02-19T09:20:41.327282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\nNow we calculate the convex hull\n","metadata":{}},{"cell_type":"code","source":"points = np.array(landmarks_points, np.int32)\nconvexhull = cv2.convexHull(points)\nprint('next')","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:20:42.755441Z","iopub.execute_input":"2022-02-19T09:20:42.756514Z","iopub.status.idle":"2022-02-19T09:20:42.763946Z","shell.execute_reply.started":"2022-02-19T09:20:42.756458Z","shell.execute_reply":"2022-02-19T09:20:42.762949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Detecting face landmark in image 2","metadata":{}},{"cell_type":"code","source":"faces2 = detector(img2_gray)\nfor face in faces2:\n  landmarks = predictor(img2_gray, face)\n  landmarks_points2 = []\n  for n in range(0, 68):\n    x = landmarks.part(n).x\n    y = landmarks.part(n).y\n    landmarks_points2.append((x, y))\n    #cv2.circle(img2, (x, y), 3, (0, 255, 0), -1) #This line help to print landmarks in the face\n    \nprint('next')","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:20:44.166978Z","iopub.execute_input":"2022-02-19T09:20:44.167587Z","iopub.status.idle":"2022-02-19T09:20:44.291668Z","shell.execute_reply.started":"2022-02-19T09:20:44.167538Z","shell.execute_reply":"2022-02-19T09:20:44.29046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"and convex hull to image 2","metadata":{}},{"cell_type":"code","source":"points2 = np.array(landmarks_points2, np.int32)\nconvexhull2 = cv2.convexHull(points2)\nprint('next')","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:20:46.676784Z","iopub.execute_input":"2022-02-19T09:20:46.677053Z","iopub.status.idle":"2022-02-19T09:20:46.683944Z","shell.execute_reply.started":"2022-02-19T09:20:46.677026Z","shell.execute_reply":"2022-02-19T09:20:46.683178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nSplitting the face into triangles\n\nWe need to divide both faces into triangles, to match the shape of both faces\nApplying Delaunay triangulation to image 1\n\n\"For morphing images the Delaunay triangulation provides a 'good' way to create a triangular mesh from points that are going to be moved. The triangular shapes are distorted from one image to the next \" from Delaunay triangulation\n","metadata":{}},{"cell_type":"code","source":"rect = cv2.boundingRect(convexhull)#find the rectangle sourrounding convex hull\nsubdiv = cv2.Subdiv2D(rect)\nsubdiv.insert(landmarks_points)\ntriangles = subdiv.getTriangleList()\ntriangles = np.array(triangles, dtype=np.int32)\nfor t in triangles:\n   pt1 = (t[0], t[1])\n   pt2 = (t[2], t[3])\n   pt3 = (t[4], t[5])\n   #cv2.line(img, pt1, pt2, (0, 0, 255), 2) #this unselected lines help o vizualize the triangles \n   #cv2.line(img, pt2, pt3, (0, 0, 255), 2) #on the face\n   #cv2.line(img, pt3, pt1, (0, 0, 255), 2)\n\nprint('next')","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:20:48.296509Z","iopub.execute_input":"2022-02-19T09:20:48.297253Z","iopub.status.idle":"2022-02-19T09:20:48.312936Z","shell.execute_reply.started":"2022-02-19T09:20:48.297207Z","shell.execute_reply":"2022-02-19T09:20:48.312268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\nwe need the next black pattern to put the face from image 1\n","metadata":{}},{"cell_type":"code","source":"img2_new_face = np.zeros_like(img2)\nplt.imshow(img2_new_face)\nplt.show","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:20:50.159336Z","iopub.execute_input":"2022-02-19T09:20:50.159681Z","iopub.status.idle":"2022-02-19T09:20:50.496695Z","shell.execute_reply.started":"2022-02-19T09:20:50.159646Z","shell.execute_reply":"2022-02-19T09:20:50.495773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\nNext is a function to extract the indexes of the triangles from the landmarks point array:\n","metadata":{}},{"cell_type":"code","source":"def extract_index_nparray(nparray):\n    index = None\n    for num in nparray[0]:\n        index = num\n        break\n    return index\nprint('next')","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:20:52.313671Z","iopub.execute_input":"2022-02-19T09:20:52.314058Z","iopub.status.idle":"2022-02-19T09:20:52.31997Z","shell.execute_reply.started":"2022-02-19T09:20:52.314012Z","shell.execute_reply":"2022-02-19T09:20:52.319206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nFinding the indexes of each triangle (or specific landmarks points each triangle connects).\n","metadata":{}},{"cell_type":"code","source":"indexes_triangles = []\nfor t in triangles:\n        pt1 = (t[0], t[1])\n        pt2 = (t[2], t[3])\n        pt3 = (t[4], t[5])\n        index_pt1 = np.where((points == pt1).all(axis=1))\n        index_pt1 = extract_index_nparray(index_pt1)\n        index_pt2 = np.where((points == pt2).all(axis=1))\n        index_pt2 = extract_index_nparray(index_pt2)\n        index_pt3 = np.where((points == pt3).all(axis=1))\n        index_pt3 = extract_index_nparray(index_pt3)\n        if index_pt1 is not None and index_pt2 is not None and index_pt3 is not None:\n            triangle = [index_pt1, index_pt2, index_pt3]\n            indexes_triangles.append(triangle)\n        #cv2.line(img, pt1, pt2, (0, 0, 255), 2)\n        #cv2.line(img, pt2, pt3, (0, 0, 255), 2)\n        #cv2.line(img, pt1, pt3, (0, 0, 255), 2)\nprint('next')","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:20:54.065987Z","iopub.execute_input":"2022-02-19T09:20:54.066772Z","iopub.status.idle":"2022-02-19T09:20:54.081784Z","shell.execute_reply.started":"2022-02-19T09:20:54.066727Z","shell.execute_reply":"2022-02-19T09:20:54.081163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nTriangulation of the 2nd face from the 1st face using Delaunay Triangulation\n","metadata":{}},{"cell_type":"code","source":"# Triangulation of both faces\nfor triangle_index in indexes_triangles:\n    # Triangulation of the first face\n    tr1_pt1 = landmarks_points[triangle_index[0]]\n    tr1_pt2 = landmarks_points[triangle_index[1]]\n    tr1_pt3 = landmarks_points[triangle_index[2]]\n    triangle1 = np.array([tr1_pt1, tr1_pt2, tr1_pt3], np.int32)\n\n    rect1 = cv2.boundingRect(triangle1)\n    (x, y, w, h) = rect1\n    cropped_triangle = img1[y: y + h, x: x + w]\n    cropped_tr1_mask = np.zeros((h, w), np.uint8)\n    points = np.array([[tr1_pt1[0] - x, tr1_pt1[1] - y],\n                      [tr1_pt2[0] - x, tr1_pt2[1] - y],\n                      [tr1_pt3[0] - x, tr1_pt3[1] - y]], np.int32)\n    cv2.fillConvexPoly(cropped_tr1_mask, points, 255)\n    cropped_triangle = cv2.bitwise_and(cropped_triangle, cropped_triangle,\n                                       mask=cropped_tr1_mask)\n    #cv2.line(img, tr1_pt1, tr1_pt2, (0, 0, 255), 2)\n    #cv2.line(img, tr1_pt3, tr1_pt2, (0, 0, 255), 2)\n    #cv2.line(img, tr1_pt1, tr1_pt3, (0, 0, 255), 2)\n\n     # Triangulation of second face\n    tr2_pt1 = landmarks_points2[triangle_index[0]]\n    tr2_pt2 = landmarks_points2[triangle_index[1]]\n    tr2_pt3 = landmarks_points2[triangle_index[2]]\n    triangle2 = np.array([tr2_pt1, tr2_pt2, tr2_pt3], np.int32)\n    rect2 = cv2.boundingRect(triangle2)\n    (x, y, w, h) = rect2\n    cropped_triangle2 = img2[y: y + h, x: x + w]\n    cropped_tr2_mask = np.zeros((h, w), np.uint8)\n    points2 = np.array([[tr2_pt1[0] - x, tr2_pt1[1] - y],\n                       [tr2_pt2[0] - x, tr2_pt2[1] - y],\n                       [tr2_pt3[0] - x, tr2_pt3[1] - y]], np.int32)\n    cv2.fillConvexPoly(cropped_tr2_mask, points2, 255)\n    cropped_triangle2 = cv2.bitwise_and(cropped_triangle2, cropped_triangle2,\n                                       mask=cropped_tr2_mask)\n    #cv2.line(img2, tr2_pt1, tr2_pt2, (0, 0, 255), 2)\n    #cv2.line(img2, tr2_pt3, tr2_pt2, (0, 0, 255), 2)\n    #cv2.line(img2, tr2_pt1, tr2_pt3, (0, 0, 255), 2)\n    \n    # Let's Warp triangles\n    points = np.float32(points)\n    points2 = np.float32(points2)\n    M = cv2.getAffineTransform(points, points2)\n    warped_triangle = cv2.warpAffine(cropped_triangle, M, (w, h))\n    warped_triangle = cv2.bitwise_and(warped_triangle, warped_triangle, mask=cropped_tr2_mask)##\n\n    # *****Reconstructing destination face************************************************\n    img2_new_face_rect_area = img2_new_face[y: y + h, x: x + w]\n    img2_new_face_rect_area_gray= cv2.cvtColor(img2_new_face_rect_area, cv2.COLOR_BGR2GRAY)\n\n    #To remove the lines between triangles\n    _, mask_triangles_designed=cv2.threshold(img2_new_face_rect_area_gray, 1, 255, cv2.THRESH_BINARY_INV)\n    warped_triangle=cv2.bitwise_and(warped_triangle, warped_triangle, mask=mask_triangles_designed)\n\n    img2_new_face_rect_area = cv2.add(img2_new_face_rect_area, warped_triangle)\n    img2_new_face[y: y + h, x: x + w] = img2_new_face_rect_area\n\n    # Face swapped (putting 1st face into 2nd face)\n    img2_face_mask = np.zeros_like(img2_gray)\n    img2_head_mask = cv2.fillConvexPoly(img2_face_mask, convexhull2, 255)\n    img2_face_mask = cv2.bitwise_not(img2_head_mask)\n\n    img2_head_noface = cv2.bitwise_and(img2, img2, mask=img2_face_mask)\n    result = cv2.add(img2_head_noface, img2_new_face)\n\n    #plt.imshow(img2_new_face)\n    #plt.imshow(result)\n    plt.imshow(result[:,:,::-1])","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:22:17.695698Z","iopub.execute_input":"2022-02-19T09:22:17.695994Z","iopub.status.idle":"2022-02-19T09:22:33.143356Z","shell.execute_reply.started":"2022-02-19T09:22:17.695965Z","shell.execute_reply":"2022-02-19T09:22:33.142548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:23:29.150271Z","iopub.execute_input":"2022-02-19T09:23:29.150681Z","iopub.status.idle":"2022-02-19T09:23:29.920621Z","shell.execute_reply.started":"2022-02-19T09:23:29.150642Z","shell.execute_reply":"2022-02-19T09:23:29.919531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imsave('/kaggle/working/save_image.jpg', result[:,:,::-1])","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:24:15.704294Z","iopub.execute_input":"2022-02-19T09:24:15.704736Z","iopub.status.idle":"2022-02-19T09:24:15.748206Z","shell.execute_reply.started":"2022-02-19T09:24:15.704697Z","shell.execute_reply":"2022-02-19T09:24:15.747206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}