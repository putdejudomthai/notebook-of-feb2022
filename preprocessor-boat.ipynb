{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n!pip install imutils\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-08T13:44:58.539494Z","iopub.execute_input":"2022-02-08T13:44:58.540586Z","iopub.status.idle":"2022-02-08T13:44:58.567424Z","shell.execute_reply.started":"2022-02-08T13:44:58.540433Z","shell.execute_reply":"2022-02-08T13:44:58.56661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define util functions","metadata":{}},{"cell_type":"code","source":"import json\nimport os\nimport tqdm\n\npath = '../input/super-ai-engineer-2021-font-recognition/'\njoin = os.path.join\n\ndef get_ground_truth(json_path):\n    data = json.load(open(json_path))\n    return data\n\ndef get_font_family_dict():\n    font = {}\n    for k,i in enumerate(os.scandir(join(path,'fonts'))):\n        name = i.name.split(\".ttf\")[0]\n        font[k] = name\n    return font\n        \ndef get_font_size_weight_style_dict():\n    size = []\n    weight = []\n    style = []\n    for i in tqdm.tqdm(os.scandir(path+'train'), os.path.getsize(path+'train')):\n        for j in os.scandir(i):\n            data = get_ground_truth(join(j.path,'gt_text.json'))\n            for ele in data:\n                ele = ele[\"style\"]\n                size.append(ele['fontSize'])\n                weight.append(ele['fontWeight'])\n                style.append(ele['fontStyle'])\n    conv = lambda x: list(set(x))\n    size, weight, style = conv(size), conv(weight), conv(style)\n    size = {i:j for i,j in enumerate(size)}\n    weight = {i:j for i,j in enumerate(weight)}\n    style = {i:j for i,j in enumerate(style)}\n    return size, weight, style\n\ndef get_label_dict():\n    ff_dict = get_font_family_dict()\n    s,w,st = get_font_size_weight_style_dict()\n    return ff_dict, s, w, st\n\ndef prepare_dataset_folder():\n    main_dir = './datasets'\n    train_dir = join(main_dir,'train')\n    test_dir = join(main_dir,'test')\n    os.makedirs(main_dir, exist_ok=True)\n    os.makedirs(train_dir, exist_ok=True)\n    os.makedirs(test_dir, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:22:24.891495Z","iopub.execute_input":"2022-02-08T14:22:24.891801Z","iopub.status.idle":"2022-02-08T14:22:24.90851Z","shell.execute_reply.started":"2022-02-08T14:22:24.891772Z","shell.execute_reply":"2022-02-08T14:22:24.907445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_font_family_dict()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:20:23.854481Z","iopub.execute_input":"2022-02-08T14:20:23.854825Z","iopub.status.idle":"2022-02-08T14:20:23.862725Z","shell.execute_reply.started":"2022-02-08T14:20:23.854792Z","shell.execute_reply":"2022-02-08T14:20:23.861985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Character cropping function using Label & Regionprops","metadata":{}},{"cell_type":"code","source":"import cv2\nimport imutils\nfrom skimage.measure import label, regionprops\n\ndef get_char_segmented_image(segment, upsamp_multiplier = 3):\n    image = segment\n    image = cv2.resize(image, (image.shape[1]*upsamp_multiplier, image.shape[0]*upsamp_multiplier), cv2.INTER_CUBIC)\n    image = cv2.adaptiveThreshold(image, 255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 21, 10)\n\n    label_img = label(image, connectivity=image.ndim)\n    props = regionprops(label_img)\n\n    rois = []\n    for prop in props:\n        box = prop.bbox\n        roi = image[box[0]:box[2], box[1]:box[3]]\n        rois.append(roi)\n            \n    return rois","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:45:31.074135Z","iopub.execute_input":"2022-02-08T13:45:31.074794Z","iopub.status.idle":"2022-02-08T13:45:31.082221Z","shell.execute_reply.started":"2022-02-08T13:45:31.07476Z","shell.execute_reply":"2022-02-08T13:45:31.081533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Regoinprops & Label example","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2\nimport imutils\nfrom skimage.measure import label, regionprops\nimport tqdm\n\nimg_ids = []\nmax_image_count = 10\ncount = 0\nfor i in os.scandir(join(path, 'train', 'set2')):\n    if count >= max_image_count: break\n    img_ids.append(i.name)\n    count += 1\n\nfor img_id in tqdm.tqdm(img_ids):\n    image = cv2.imread(join(path,'train','set1',str(img_id),'image.png'),0)\n    js = json.load(open(join(path,'train','set1',str(img_id),'gt_text.json')))\n    rect = js[0][\"rect\"]\n    image = image[int(rect[\"y\"]):int(rect[\"y\"]+rect[\"height\"]), int(rect[\"x\"]):int(rect[\"x\"]+rect[\"width\"])]\n    image = cv2.resize(image, (image.shape[1]*3, image.shape[0]*3), cv2.INTER_CUBIC)\n    image = cv2.adaptiveThreshold(image, 255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 21, 10)\n    contours, hierarchy = cv2.findContours(image,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n\n    clone = image.copy()\n\n    i = 0\n\n    fig = plt.figure(figsize=(15, 7))\n\n    label_img = label(image, connectivity=image.ndim)\n    props = regionprops(label_img)\n\n    for prop in props:\n        i = i+1\n        box = prop.bbox\n        roi = image[box[0]:box[2], box[1]:box[3]]\n        fig.add_subplot(1, len(props), i)\n        plt.imshow(roi)\n        plt.axis('off') \n    \n    i = 0\n\n    for cnt in contours:\n        i = i+1\n        x,y,w,h = cv2.boundingRect(cnt)\n        roi = image[y:y+h, x:x+w]\n        fig.add_subplot(2, len(contours), i)\n        plt.imshow(roi)\n        plt.axis('off') \n\n    fig2 = plt.figure(figsize=(10, 7))\n    fig2.add_subplot(3, 1, 1)\n    plt.imshow(image)\n    plt.axis('off') ","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:45:33.247168Z","iopub.execute_input":"2022-02-08T13:45:33.24747Z","iopub.status.idle":"2022-02-08T13:46:04.454498Z","shell.execute_reply.started":"2022-02-08T13:45:33.24743Z","shell.execute_reply":"2022-02-08T13:46:04.453105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess Datasets****","metadata":{}},{"cell_type":"code","source":"!rm -rf ./datasets","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:14:32.838244Z","iopub.execute_input":"2022-02-08T15:14:32.839115Z","iopub.status.idle":"2022-02-08T15:14:34.999706Z","shell.execute_reply.started":"2022-02-08T15:14:32.839058Z","shell.execute_reply":"2022-02-08T15:14:34.998252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prepare_dataset_folder()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:14:35.003151Z","iopub.execute_input":"2022-02-08T15:14:35.003546Z","iopub.status.idle":"2022-02-08T15:14:35.00951Z","shell.execute_reply.started":"2022-02-08T15:14:35.003497Z","shell.execute_reply":"2022-02-08T15:14:35.008348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\n\ndataset_path = '../input/w1n1-data'\noutput_path = './datasets'\nsplit_size = 0.7\nprint(os.listdir(dataset_path))\n\ndf = pd.read_csv(join(dataset_path, 'df.csv'))\n\ndf = df.sample(frac=1).reset_index(drop=True)\nprint(df.head())\nprint(len(df))\n\nseg_count = 0\nsplit_pos = int(len(df) * split_size)\n\nprint('processing train dataset...')\ncreated_folder = []\nfor k,v in tqdm(df.loc[0:split_pos].iterrows(), total = len(df.loc[0:split_pos])):\n    file = v[\"file\"]\n    font_family = v['fontFamily']\n    image_path = join(dataset_path, 'crop_images', file)\n    image = cv2.imread(image_path,0)\n    segmented = get_char_segmented_image(image, upsamp_multiplier = 3)\n    seg_count += len(segmented)\n    save_path = join(output_path, 'train', font_family)\n    if font_family not in created_folder:\n        os.makedirs(save_path)\n        created_folder.append(font_family)\n    for counter, seg in enumerate(segmented):\n        cv2.imwrite(join(save_path, f'{file}_{counter}'), seg)\n        \n        \nprint('processing test dataset...')\ncreated_folder = []\nfor k,v in tqdm(df.loc[split_pos:].iterrows(), total = len(df.loc[split_pos:])):\n    file = v[\"file\"]\n    font_family = v['fontFamily']\n    image_path = join(dataset_path, 'crop_images', file)\n    image = cv2.imread(image_path,0)\n    segmented = get_char_segmented_image(image, upsamp_multiplier = 3)\n#     print(len(segmented))\n    seg_count += len(segmented)\n    save_path = join(output_path, 'test', font_family)\n    if font_family not in created_folder:\n        os.makedirs(save_path)\n        created_folder.append(font_family)\n    for counter, seg in enumerate(segmented):\n        cv2.imwrite(join(save_path, f'{file}_{counter}'), seg)\n    \n                                    ","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:14:35.011251Z","iopub.execute_input":"2022-02-08T15:14:35.01159Z","iopub.status.idle":"2022-02-08T15:32:36.77591Z","shell.execute_reply.started":"2022-02-08T15:14:35.011546Z","shell.execute_reply":"2022-02-08T15:32:36.774478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(split_pos)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:13:19.354649Z","iopub.execute_input":"2022-02-08T15:13:19.355318Z","iopub.status.idle":"2022-02-08T15:13:19.360201Z","shell.execute_reply.started":"2022-02-08T15:13:19.355273Z","shell.execute_reply":"2022-02-08T15:13:19.359353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = './datasets/train/'\ntest_path = './datasets/test/'\n\nprint('train dataset')\nfor p in os.scandir(train_path):\n    print(p.name, \" : \", len(list(os.listdir(p.path))))\nprint()\nprint('test dataset')\nfor p in os.scandir(test_path):\n    print(p.name, \" : \", len(list(os.listdir(p.path))))\n","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:44:34.546767Z","iopub.execute_input":"2022-02-08T15:44:34.547215Z","iopub.status.idle":"2022-02-08T15:44:35.590584Z","shell.execute_reply.started":"2022-02-08T15:44:34.547179Z","shell.execute_reply":"2022-02-08T15:44:35.5894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir(r'/kaggle/working')\nfrom IPython.display import FileLinks\nFileLinks('./datasets/train/')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:47:52.848464Z","iopub.execute_input":"2022-02-08T15:47:52.849239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\n\nos.makedirs(\"dataset\")\ndef crop_image():\n    size = []\n    weight = []\n    style = []\n    for i in tqdm.tqdm(os.scandir(path+'train'), os.path.getsize(path+'train')):\n        for j in os.scandir(i):\n            data = get_ground_truth(join(j.path,'gt_text.json'))\n            image = cv2.imread(join(j.path,'image.png',0))\n            id = j.name\n            for ele in data:\n                rect = ele[\"rect\"]\n                cropped = image[int(rect[\"y\"]):int(rect[\"y\"]+rect[\"height\"]), int(rect[\"x\"]):int(rect[\"x\"]+rect[\"width\"])]\n                \n                \n                \n                ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\n\nclass FontFamilyGenerator(keras.utils.Sequence):\n    def __init__(self, ids, path=path, batch_size=32, dim, n_channels,\n                 n_classes, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.ids = ids\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.path = path\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.ids) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        list_IDs_temp = [self.ids[k] for k in indexes]\n\n        X, y = self.__data_generation(list_IDs_temp)\n\n        return X, y\n\n    def on_epoch_end(self):\n        if self.shuffle == True:\n            np.random.shuffle(self.ids)\n\n    def __data_generation(self, list_IDs_temp):\n        X,Y = [],[]\n        for i in list_IDs_temp:\n            img_path = join(self.path, 'train','set1' , str(i))\n            if os.path.exist(image_path): \n                image = cv2.imread(img_path, 0)\n                label = json.load(open(join(img_path, 'gt_text.json')))\n            else: \n                img_path = join(self.path, 'train','set0' , str(i))\n                image = cv2.imread(join(img_path,'image.png'), 0)\n            X.append(image)\n            Y\n            \n\n        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n            ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}