{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Data management\nimport numpy as np\nimport pandas as pd\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nimport cv2\nimport re\nimport string\nimport os\nfrom tqdm import tqdm\n\n#Model management\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers,models\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\nimport torch\nimport joblib\n\n#data visualize\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom PIL import Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-08T02:28:34.985019Z","iopub.execute_input":"2022-02-08T02:28:34.98605Z","iopub.status.idle":"2022-02-08T02:28:34.995835Z","shell.execute_reply.started":"2022-02-08T02:28:34.985988Z","shell.execute_reply":"2022-02-08T02:28:34.994477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    os.mkdir(\"crop_images\")\nexcept:\n    pass","metadata":{"execution":{"iopub.status.busy":"2022-02-08T02:28:35.084094Z","iopub.execute_input":"2022-02-08T02:28:35.084872Z","iopub.status.idle":"2022-02-08T02:28:35.091538Z","shell.execute_reply.started":"2022-02-08T02:28:35.084803Z","shell.execute_reply":"2022-02-08T02:28:35.090154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img(idim,floderpath):\n    imtarget = floderpath + idim\n    impath = imtarget + \"/image.png\"\n    dfpath = imtarget + \"/gt_text.json\"\n    \n    im = cv2.imread(impath)\n    im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY )\n    im = cv2.adaptiveThreshold(im,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\n    df = pd.read_json(dfpath)\n    num = df.shape[0]\n    \n    image_list = []\n    filename_list = []\n    fontFamily_list = []\n    fontSize_list = []\n    fontStyle_list = []\n    fontVarient_list = []\n    fontWeight_list = []\n    h_list = []\n    w_list = []\n    text_list= []\n    parentId_list=[]\n    \n    for i in range(num):\n        if df[\"text\"][i].strip(\"_.)(][}{\\\\/:\") != \"\":\n            x  = df[\"rect\"][i][\"x\"]\n            y  = df[\"rect\"][i][\"y\"]\n            width  = df[\"rect\"][i][\"width\"]\n            height  = df[\"rect\"][i][\"height\"]\n            if y > im.shape[0] or x > im.shape[1]:\n                pass\n            else:\n                image = np.array(im[int(y)-3:int(y+height)+3,int(x)-3:int(x+width)+3])\n                imagename = idim +\"_\" + df[\"parentId\"][i]\n                #image_list.append(image)\n                cv2.imwrite(f\"./crop_images/{imagename}.png\",image)\n\n                #append\n                image_list.append(imagename)\n                filename_list.append(f\"{imagename}.png\")\n                fontFamily_list.append(df[\"style\"][i][\"fontFamily\"])\n                fontSize_list.append(df[\"style\"][i][\"fontSize\"])\n                fontStyle_list.append(df[\"style\"][i][\"fontStyle\"])\n                fontWeight_list.append(df[\"style\"][i][\"fontWeight\"])\n                h_list.append(height)\n                w_list.append(width)\n                text_list.append(df[\"text\"][i])\n                parentId_list.append(df[\"parentId\"][i])\n        \n\n    #df[\"images\"] = np.array(image_list)\n    dfn = pd.DataFrame(image_list,columns =['imagename'])\n    dfn[\"file\"] = pd.Series(filename_list)   \n    dfn[\"parentId\"] = pd.Series(parentId_list)\n    dfn[\"text\"] = pd.Series(text_list)\n    dfn[\"fontFamily\"] = pd.Series(fontFamily_list)\n    dfn[\"fontSize\"] = pd.Series(fontSize_list)\n    dfn[\"fontStyle\"] = pd.Series(fontStyle_list)\n    dfn[\"fontWeight\"] = pd.Series(fontWeight_list)\n    dfn[\"h\"] = pd.Series(h_list)\n    dfn[\"w\"] = pd.Series(w_list)\n    dfn[\"Id\"] = idim\n    return dfn","metadata":{"execution":{"iopub.status.busy":"2022-02-08T02:28:35.093268Z","iopub.execute_input":"2022-02-08T02:28:35.093583Z","iopub.status.idle":"2022-02-08T02:28:35.117703Z","shell.execute_reply.started":"2022-02-08T02:28:35.093548Z","shell.execute_reply":"2022-02-08T02:28:35.116358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"```\nfloderpath = \"../input/super-ai-engineer-2021-font-recognition/train/set1/\"\nfilelist = os.listdir(floderpath)\ndf1 = get_img(filelist[0],floderpath)\nfor i in tqdm(range(len(filelist))):\n    idim = filelist[i]\n    if idim != filelist[0]:\n        df3 = get_img(idim,floderpath)\n        df1 = df1.append(df3,ignore_index=True)\n```","metadata":{}},{"cell_type":"code","source":"floderpath = \"../input/super-ai-engineer-2021-font-recognition/train/set1/\"\nfilelist = os.listdir(floderpath)\ndf1 = get_img(filelist[0],floderpath)\nfor i in tqdm(range(len(filelist))):\n    idim = filelist[i]\n    if idim != filelist[0]:\n        df3 = get_img(idim,floderpath)\n        df1 = df1.append(df3,ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T02:28:35.120507Z","iopub.execute_input":"2022-02-08T02:28:35.121088Z","iopub.status.idle":"2022-02-08T02:32:53.547747Z","shell.execute_reply.started":"2022-02-08T02:28:35.121035Z","shell.execute_reply":"2022-02-08T02:32:53.54689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"floderpath = \"../input/super-ai-engineer-2021-font-recognition/train/set2/\"\nfilelist = os.listdir(floderpath)\nfor i in tqdm(range(len(filelist))):\n    idim = filelist[i]\n    df3 = get_img(idim,floderpath)\n    df1 = df1.append(df3,ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T02:32:53.549138Z","iopub.execute_input":"2022-02-08T02:32:53.550076Z","iopub.status.idle":"2022-02-08T02:34:25.715792Z","shell.execute_reply.started":"2022-02-08T02:32:53.550028Z","shell.execute_reply":"2022-02-08T02:34:25.714902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.to_csv(\"df.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T02:34:25.717194Z","iopub.execute_input":"2022-02-08T02:34:25.717562Z","iopub.status.idle":"2022-02-08T02:34:27.507256Z","shell.execute_reply.started":"2022-02-08T02:34:25.717514Z","shell.execute_reply":"2022-02-08T02:34:27.506198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"floderpath = \"./crop_images\"\nfilelist = os.listdir(floderpath)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T02:34:27.509039Z","iopub.execute_input":"2022-02-08T02:34:27.509492Z","iopub.status.idle":"2022-02-08T02:34:27.610969Z","shell.execute_reply.started":"2022-02-08T02:34:27.50943Z","shell.execute_reply":"2022-02-08T02:34:27.610237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-08T02:43:02.227997Z","iopub.execute_input":"2022-02-08T02:43:02.229705Z","iopub.status.idle":"2022-02-08T02:43:02.239834Z","shell.execute_reply.started":"2022-02-08T02:43:02.229627Z","shell.execute_reply":"2022-02-08T02:43:02.238949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(filelist)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T02:43:03.794754Z","iopub.execute_input":"2022-02-08T02:43:03.795059Z","iopub.status.idle":"2022-02-08T02:43:03.800627Z","shell.execute_reply.started":"2022-02-08T02:43:03.795026Z","shell.execute_reply":"2022-02-08T02:43:03.799816Z"},"trusted":true},"execution_count":null,"outputs":[]}]}